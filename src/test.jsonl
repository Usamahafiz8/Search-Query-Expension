{"repo": "soimort/you-get", "path": "src/you_get/extractors/youtube.py", "func_name": "YouTube.get_vid_from_url", "original_string": "def get_vid_from_url(url):\n        \"\"\"Extracts video ID from URL.\n        \"\"\"\n        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n          parse_query_param(url, 'v') or \\\n          parse_query_param(parse_query_param(url, 'u'), 'v')", "language": "python", "code": "def get_vid_from_url(url):\n        \"\"\"Extracts video ID from URL.\n        \"\"\"\n        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n          parse_query_param(url, 'v') or \\\n          parse_query_param(parse_query_param(url, 'u'), 'v')", "code_tokens": ["def", "get_vid_from_url", "(", "url", ")", ":", "return", "match1", "(", "url", ",", "r'youtu\\.be/([^?/]+)'", ")", "or", "match1", "(", "url", ",", "r'youtube\\.com/embed/([^/?]+)'", ")", "or", "match1", "(", "url", ",", "r'youtube\\.com/v/([^/?]+)'", ")", "or", "match1", "(", "url", ",", "r'youtube\\.com/watch/([^/?]+)'", ")", "or", "parse_query_param", "(", "url", ",", "'v'", ")", "or", "parse_query_param", "(", "parse_query_param", "(", "url", ",", "'u'", ")", ",", "'v'", ")"], "docstring": "Extracts video ID from URL.", "docstring_tokens": ["Extracts", "video", "ID", "from", "URL", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/miomio.py", "func_name": "sina_xml_to_url_list", "original_string": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl", "language": "python", "code": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl", "code_tokens": ["def", "sina_xml_to_url_list", "(", "xml_data", ")", ":", "rawurl", "=", "[", "]", "dom", "=", "parseString", "(", "xml_data", ")", "for", "node", "in", "dom", ".", "getElementsByTagName", "(", "'durl'", ")", ":", "url", "=", "node", ".", "getElementsByTagName", "(", "'url'", ")", "[", "0", "]", "rawurl", ".", "append", "(", "url", ".", "childNodes", "[", "0", "]", ".", "data", ")", "return", "rawurl"], "docstring": "str->list\n    Convert XML to URL List.\n    From Biligrab.", "docstring_tokens": ["str", "-", ">", "list", "Convert", "XML", "to", "URL", "List", ".", "From", "Biligrab", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miomio.py#L41-L51", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/fc2video.py", "func_name": "makeMimi", "original_string": "def makeMimi(upid):\n    \"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\n    L110\"\"\"\n    strSeed = \"gGddgPfeaf_gzyr\"\n    prehash = upid + \"_\" + strSeed\n    return md5(prehash.encode('utf-8')).hexdigest()", "language": "python", "code": "def makeMimi(upid):\n    \"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\n    L110\"\"\"\n    strSeed = \"gGddgPfeaf_gzyr\"\n    prehash = upid + \"_\" + strSeed\n    return md5(prehash.encode('utf-8')).hexdigest()", "code_tokens": ["def", "makeMimi", "(", "upid", ")", ":", "strSeed", "=", "\"gGddgPfeaf_gzyr\"", "prehash", "=", "upid", "+", "\"_\"", "+", "strSeed", "return", "md5", "(", "prehash", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")"], "docstring": "From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\n    L110", "docstring_tokens": ["From", "http", ":", "//", "cdn37", ".", "atwikiimg", ".", "com", "/", "sitescript", "/", "pub", "/", "dksitescript", "/", "FC2", ".", "site", ".", "js", "Also", "com", ".", "hps", ".", "util", ".", "fc2", ".", "FC2EncrptUtil", ".", "makeMimiLocal", "L110"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/fc2video.py#L11-L17", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/fc2video.py", "func_name": "fc2video_download", "original_string": "def fc2video_download(url, output_dir = '.', merge = True, info_only = False, **kwargs):\n    \"\"\"wrapper\"\"\"\n    #'http://video.fc2.com/en/content/20151021bTVKnbEw'\n    #'http://xiaojiadianvideo.asia/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/ja/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/tw/content/20151021bTVKnbEw'\n    hostname = urlparse(url).hostname\n    if not ('fc2.com' in hostname or 'xiaojiadianvideo.asia' in hostname):\n        return False\n    upid = match1(url, r'.+/content/(\\w+)')\n\n    fc2video_download_by_upid(upid, output_dir, merge, info_only)", "language": "python", "code": "def fc2video_download(url, output_dir = '.', merge = True, info_only = False, **kwargs):\n    \"\"\"wrapper\"\"\"\n    #'http://video.fc2.com/en/content/20151021bTVKnbEw'\n    #'http://xiaojiadianvideo.asia/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/ja/content/20151021bTVKnbEw'\n    #'http://video.fc2.com/tw/content/20151021bTVKnbEw'\n    hostname = urlparse(url).hostname\n    if not ('fc2.com' in hostname or 'xiaojiadianvideo.asia' in hostname):\n        return False\n    upid = match1(url, r'.+/content/(\\w+)')\n\n    fc2video_download_by_upid(upid, output_dir, merge, info_only)", "code_tokens": ["def", "fc2video_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "#'http://video.fc2.com/en/content/20151021bTVKnbEw'", "#'http://xiaojiadianvideo.asia/content/20151021bTVKnbEw'", "#'http://video.fc2.com/ja/content/20151021bTVKnbEw'", "#'http://video.fc2.com/tw/content/20151021bTVKnbEw'", "hostname", "=", "urlparse", "(", "url", ")", ".", "hostname", "if", "not", "(", "'fc2.com'", "in", "hostname", "or", "'xiaojiadianvideo.asia'", "in", "hostname", ")", ":", "return", "False", "upid", "=", "match1", "(", "url", ",", "r'.+/content/(\\w+)'", ")", "fc2video_download_by_upid", "(", "upid", ",", "output_dir", ",", "merge", ",", "info_only", ")"], "docstring": "wrapper", "docstring_tokens": ["wrapper"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/fc2video.py#L46-L57", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/dailymotion.py", "func_name": "dailymotion_download", "original_string": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)", "language": "python", "code": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)", "code_tokens": ["def", "dailymotion_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "html", "=", "get_content", "(", "rebuilt_url", "(", "url", ")", ")", "info", "=", "json", ".", "loads", "(", "match1", "(", "html", ",", "r'qualities\":({.+?}),\"'", ")", ")", "title", "=", "match1", "(", "html", ",", "r'\"video_title\"\\s*:\\s*\"([^\"]+)\"'", ")", "or", "match1", "(", "html", ",", "r'\"title\"\\s*:\\s*\"([^\"]+)\"'", ")", "title", "=", "unicodize", "(", "title", ")", "for", "quality", "in", "[", "'1080'", ",", "'720'", ",", "'480'", ",", "'380'", ",", "'240'", ",", "'144'", ",", "'auto'", "]", ":", "try", ":", "real_url", "=", "info", "[", "quality", "]", "[", "1", "]", "[", "\"url\"", "]", "if", "real_url", ":", "break", "except", "KeyError", ":", "pass", "mime", ",", "ext", ",", "size", "=", "url_info", "(", "real_url", ")", "print_info", "(", "site_info", ",", "title", ",", "mime", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "[", "real_url", "]", ",", "title", ",", "ext", ",", "size", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "Downloads Dailymotion videos by URL.", "docstring_tokens": ["Downloads", "Dailymotion", "videos", "by", "URL", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/dailymotion.py#L13-L35", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/ucas.py", "func_name": "dictify", "original_string": "def dictify(r,root=True):\n    \"\"\"http://stackoverflow.com/a/30923963/2946714\"\"\"\n    if root:\n        return {r.tag : dictify(r, False)}\n    d=copy(r.attrib)\n    if r.text:\n        d[\"_text\"]=r.text\n    for x in r.findall(\"./*\"):\n        if x.tag not in d:\n            d[x.tag]=[]\n        d[x.tag].append(dictify(x,False))\n    return d", "language": "python", "code": "def dictify(r,root=True):\n    \"\"\"http://stackoverflow.com/a/30923963/2946714\"\"\"\n    if root:\n        return {r.tag : dictify(r, False)}\n    d=copy(r.attrib)\n    if r.text:\n        d[\"_text\"]=r.text\n    for x in r.findall(\"./*\"):\n        if x.tag not in d:\n            d[x.tag]=[]\n        d[x.tag].append(dictify(x,False))\n    return d", "code_tokens": ["def", "dictify", "(", "r", ",", "root", "=", "True", ")", ":", "if", "root", ":", "return", "{", "r", ".", "tag", ":", "dictify", "(", "r", ",", "False", ")", "}", "d", "=", "copy", "(", "r", ".", "attrib", ")", "if", "r", ".", "text", ":", "d", "[", "\"_text\"", "]", "=", "r", ".", "text", "for", "x", "in", "r", ".", "findall", "(", "\"./*\"", ")", ":", "if", "x", ".", "tag", "not", "in", "d", ":", "d", "[", "x", ".", "tag", "]", "=", "[", "]", "d", "[", "x", ".", "tag", "]", ".", "append", "(", "dictify", "(", "x", ",", "False", ")", ")", "return", "d"], "docstring": "http://stackoverflow.com/a/30923963/2946714", "docstring_tokens": ["http", ":", "//", "stackoverflow", ".", "com", "/", "a", "/", "30923963", "/", "2946714"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ucas.py#L18-L29", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/ucas.py", "func_name": "ucas_download_single", "original_string": "def ucas_download_single(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''video page'''\n    html = get_content(url)\n    # resourceID is UUID\n    resourceID = re.findall( r'resourceID\":\"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})', html)[0]\n    assert resourceID != '', 'Cannot find resourceID!'\n\n    title = match1(html, r'<div class=\"bc-h\">(.+)</div>')\n    url_lists = _ucas_get_url_lists_by_resourceID(resourceID)\n    assert url_lists, 'Cannot find any URL of such class!'\n    \n    for k, part in enumerate(url_lists):\n        part_title = title + '_' + str(k)\n        print_info(site_info, part_title, 'flv', 0)\n        if not info_only:\n            download_urls(part, part_title, 'flv', total_size=None, output_dir=output_dir, merge=merge)", "language": "python", "code": "def ucas_download_single(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''video page'''\n    html = get_content(url)\n    # resourceID is UUID\n    resourceID = re.findall( r'resourceID\":\"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})', html)[0]\n    assert resourceID != '', 'Cannot find resourceID!'\n\n    title = match1(html, r'<div class=\"bc-h\">(.+)</div>')\n    url_lists = _ucas_get_url_lists_by_resourceID(resourceID)\n    assert url_lists, 'Cannot find any URL of such class!'\n    \n    for k, part in enumerate(url_lists):\n        part_title = title + '_' + str(k)\n        print_info(site_info, part_title, 'flv', 0)\n        if not info_only:\n            download_urls(part, part_title, 'flv', total_size=None, output_dir=output_dir, merge=merge)", "code_tokens": ["def", "ucas_download_single", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "html", "=", "get_content", "(", "url", ")", "# resourceID is UUID", "resourceID", "=", "re", ".", "findall", "(", "r'resourceID\":\"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})'", ",", "html", ")", "[", "0", "]", "assert", "resourceID", "!=", "''", ",", "'Cannot find resourceID!'", "title", "=", "match1", "(", "html", ",", "r'<div class=\"bc-h\">(.+)</div>'", ")", "url_lists", "=", "_ucas_get_url_lists_by_resourceID", "(", "resourceID", ")", "assert", "url_lists", ",", "'Cannot find any URL of such class!'", "for", "k", ",", "part", "in", "enumerate", "(", "url_lists", ")", ":", "part_title", "=", "title", "+", "'_'", "+", "str", "(", "k", ")", "print_info", "(", "site_info", ",", "part_title", ",", "'flv'", ",", "0", ")", "if", "not", "info_only", ":", "download_urls", "(", "part", ",", "part_title", ",", "'flv'", ",", "total_size", "=", "None", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "video page", "docstring_tokens": ["video", "page"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ucas.py#L102-L117", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/ucas.py", "func_name": "ucas_download_playlist", "original_string": "def ucas_download_playlist(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''course page'''\n    html = get_content(url)\n\n    parts = re.findall( r'(getplaytitle.do\\?.+)\"', html)\n    assert parts, 'No part found!'\n\n    for part_path in parts:\n        ucas_download('http://v.ucas.ac.cn/course/' + part_path, output_dir=output_dir, merge=merge, info_only=info_only)", "language": "python", "code": "def ucas_download_playlist(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''course page'''\n    html = get_content(url)\n\n    parts = re.findall( r'(getplaytitle.do\\?.+)\"', html)\n    assert parts, 'No part found!'\n\n    for part_path in parts:\n        ucas_download('http://v.ucas.ac.cn/course/' + part_path, output_dir=output_dir, merge=merge, info_only=info_only)", "code_tokens": ["def", "ucas_download_playlist", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "html", "=", "get_content", "(", "url", ")", "parts", "=", "re", ".", "findall", "(", "r'(getplaytitle.do\\?.+)\"'", ",", "html", ")", "assert", "parts", ",", "'No part found!'", "for", "part_path", "in", "parts", ":", "ucas_download", "(", "'http://v.ucas.ac.cn/course/'", "+", "part_path", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")"], "docstring": "course page", "docstring_tokens": ["course", "page"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ucas.py#L119-L127", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/sina.py", "func_name": "sina_download_by_vid", "original_string": "def sina_download_by_vid(vid, title=None, output_dir='.', merge=True, info_only=False):\n    \"\"\"Downloads a Sina video by its unique vid.\n    http://video.sina.com.cn/\n    \"\"\"\n    xml = api_req(vid)\n    urls, name, size = video_info(xml)\n    if urls is None:\n        log.wtf(name)\n    title = name\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls(urls, title, 'flv', size, output_dir = output_dir, merge = merge)", "language": "python", "code": "def sina_download_by_vid(vid, title=None, output_dir='.', merge=True, info_only=False):\n    \"\"\"Downloads a Sina video by its unique vid.\n    http://video.sina.com.cn/\n    \"\"\"\n    xml = api_req(vid)\n    urls, name, size = video_info(xml)\n    if urls is None:\n        log.wtf(name)\n    title = name\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls(urls, title, 'flv', size, output_dir = output_dir, merge = merge)", "code_tokens": ["def", "sina_download_by_vid", "(", "vid", ",", "title", "=", "None", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ")", ":", "xml", "=", "api_req", "(", "vid", ")", "urls", ",", "name", ",", "size", "=", "video_info", "(", "xml", ")", "if", "urls", "is", "None", ":", "log", ".", "wtf", "(", "name", ")", "title", "=", "name", "print_info", "(", "site_info", ",", "title", ",", "'flv'", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "urls", ",", "title", ",", "'flv'", ",", "size", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "Downloads a Sina video by its unique vid.\n    http://video.sina.com.cn/", "docstring_tokens": ["Downloads", "a", "Sina", "video", "by", "its", "unique", "vid", ".", "http", ":", "//", "video", ".", "sina", ".", "com", ".", "cn", "/"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/sina.py#L41-L52", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/sina.py", "func_name": "sina_download_by_vkey", "original_string": "def sina_download_by_vkey(vkey, title=None, output_dir='.', merge=True, info_only=False):\n    \"\"\"Downloads a Sina video by its unique vkey.\n    http://video.sina.com/\n    \"\"\"\n\n    url = 'http://video.sina.com/v/flvideo/%s_0.flv' % vkey\n    type, ext, size = url_info(url)\n\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls([url], title, 'flv', size, output_dir = output_dir, merge = merge)", "language": "python", "code": "def sina_download_by_vkey(vkey, title=None, output_dir='.', merge=True, info_only=False):\n    \"\"\"Downloads a Sina video by its unique vkey.\n    http://video.sina.com/\n    \"\"\"\n\n    url = 'http://video.sina.com/v/flvideo/%s_0.flv' % vkey\n    type, ext, size = url_info(url)\n\n    print_info(site_info, title, 'flv', size)\n    if not info_only:\n        download_urls([url], title, 'flv', size, output_dir = output_dir, merge = merge)", "code_tokens": ["def", "sina_download_by_vkey", "(", "vkey", ",", "title", "=", "None", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ")", ":", "url", "=", "'http://video.sina.com/v/flvideo/%s_0.flv'", "%", "vkey", "type", ",", "ext", ",", "size", "=", "url_info", "(", "url", ")", "print_info", "(", "site_info", ",", "title", ",", "'flv'", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "[", "url", "]", ",", "title", ",", "'flv'", ",", "size", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "Downloads a Sina video by its unique vkey.\n    http://video.sina.com/", "docstring_tokens": ["Downloads", "a", "Sina", "video", "by", "its", "unique", "vkey", ".", "http", ":", "//", "video", ".", "sina", ".", "com", "/"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/sina.py#L54-L64", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/sina.py", "func_name": "sina_download", "original_string": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)", "language": "python", "code": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)", "code_tokens": ["def", "sina_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "if", "'news.sina.com.cn/zxt'", "in", "url", ":", "sina_zxt", "(", "url", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ",", "*", "*", "kwargs", ")", "return", "vid", "=", "match1", "(", "url", ",", "r'vid=(\\d+)'", ")", "if", "vid", "is", "None", ":", "video_page", "=", "get_content", "(", "url", ")", "vid", "=", "hd_vid", "=", "match1", "(", "video_page", ",", "r'hd_vid\\s*:\\s*\\'([^\\']+)\\''", ")", "if", "hd_vid", "==", "'0'", ":", "vids", "=", "match1", "(", "video_page", ",", "r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\''", ")", ".", "split", "(", "'|'", ")", "vid", "=", "vids", "[", "-", "1", "]", "if", "vid", "is", "None", ":", "vid", "=", "match1", "(", "video_page", ",", "r'vid:\"?(\\d+)\"?'", ")", "if", "vid", ":", "#title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')", "sina_download_by_vid", "(", "vid", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "else", ":", "vkey", "=", "match1", "(", "video_page", ",", "r'vkey\\s*:\\s*\"([^\"]+)\"'", ")", "if", "vkey", "is", "None", ":", "vid", "=", "match1", "(", "url", ",", "r'#(\\d+)'", ")", "sina_download_by_vid", "(", "vid", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "return", "title", "=", "match1", "(", "video_page", ",", "r'title\\s*:\\s*\"([^\"]+)\"'", ")", "sina_download_by_vkey", "(", "vkey", ",", "title", "=", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")"], "docstring": "Downloads Sina videos by URL.", "docstring_tokens": ["Downloads", "Sina", "videos", "by", "URL", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/sina.py#L94-L121", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/yixia.py", "func_name": "yixia_download", "original_string": "def yixia_download(url, output_dir = '.', merge = True, info_only = False, **kwargs):\n    \"\"\"wrapper\"\"\"\n    hostname = urlparse(url).hostname\n    if 'n.miaopai.com' == hostname: \n        smid = match1(url, r'n\\.miaopai\\.com/media/([^.]+)') \n        miaopai_download_by_smid(smid, output_dir, merge, info_only)\n        return\n    elif 'miaopai.com' in hostname:  #Miaopai\n        yixia_download_by_scid = yixia_miaopai_download_by_scid\n        site_info = \"Yixia Miaopai\"\n\n        scid = match1(url, r'miaopai\\.com/show/channel/([^.]+)\\.htm') or \\\n               match1(url, r'miaopai\\.com/show/([^.]+)\\.htm') or \\\n               match1(url, r'm\\.miaopai\\.com/show/channel/([^.]+)\\.htm') or \\\n               match1(url, r'm\\.miaopai\\.com/show/channel/([^.]+)')\n\n    elif 'xiaokaxiu.com' in hostname:  #Xiaokaxiu\n        yixia_download_by_scid = yixia_xiaokaxiu_download_by_scid\n        site_info = \"Yixia Xiaokaxiu\"\n\n        if re.match(r'http://v.xiaokaxiu.com/v/.+\\.html', url):  #PC\n            scid = match1(url, r'http://v.xiaokaxiu.com/v/(.+)\\.html')\n        elif re.match(r'http://m.xiaokaxiu.com/m/.+\\.html', url):  #Mobile\n            scid = match1(url, r'http://m.xiaokaxiu.com/m/(.+)\\.html')\n\n    else:\n        pass\n\n    yixia_download_by_scid(scid, output_dir, merge, info_only)", "language": "python", "code": "def yixia_download(url, output_dir = '.', merge = True, info_only = False, **kwargs):\n    \"\"\"wrapper\"\"\"\n    hostname = urlparse(url).hostname\n    if 'n.miaopai.com' == hostname: \n        smid = match1(url, r'n\\.miaopai\\.com/media/([^.]+)') \n        miaopai_download_by_smid(smid, output_dir, merge, info_only)\n        return\n    elif 'miaopai.com' in hostname:  #Miaopai\n        yixia_download_by_scid = yixia_miaopai_download_by_scid\n        site_info = \"Yixia Miaopai\"\n\n        scid = match1(url, r'miaopai\\.com/show/channel/([^.]+)\\.htm') or \\\n               match1(url, r'miaopai\\.com/show/([^.]+)\\.htm') or \\\n               match1(url, r'm\\.miaopai\\.com/show/channel/([^.]+)\\.htm') or \\\n               match1(url, r'm\\.miaopai\\.com/show/channel/([^.]+)')\n\n    elif 'xiaokaxiu.com' in hostname:  #Xiaokaxiu\n        yixia_download_by_scid = yixia_xiaokaxiu_download_by_scid\n        site_info = \"Yixia Xiaokaxiu\"\n\n        if re.match(r'http://v.xiaokaxiu.com/v/.+\\.html', url):  #PC\n            scid = match1(url, r'http://v.xiaokaxiu.com/v/(.+)\\.html')\n        elif re.match(r'http://m.xiaokaxiu.com/m/.+\\.html', url):  #Mobile\n            scid = match1(url, r'http://m.xiaokaxiu.com/m/(.+)\\.html')\n\n    else:\n        pass\n\n    yixia_download_by_scid(scid, output_dir, merge, info_only)", "code_tokens": ["def", "yixia_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "hostname", "=", "urlparse", "(", "url", ")", ".", "hostname", "if", "'n.miaopai.com'", "==", "hostname", ":", "smid", "=", "match1", "(", "url", ",", "r'n\\.miaopai\\.com/media/([^.]+)'", ")", "miaopai_download_by_smid", "(", "smid", ",", "output_dir", ",", "merge", ",", "info_only", ")", "return", "elif", "'miaopai.com'", "in", "hostname", ":", "#Miaopai", "yixia_download_by_scid", "=", "yixia_miaopai_download_by_scid", "site_info", "=", "\"Yixia Miaopai\"", "scid", "=", "match1", "(", "url", ",", "r'miaopai\\.com/show/channel/([^.]+)\\.htm'", ")", "or", "match1", "(", "url", ",", "r'miaopai\\.com/show/([^.]+)\\.htm'", ")", "or", "match1", "(", "url", ",", "r'm\\.miaopai\\.com/show/channel/([^.]+)\\.htm'", ")", "or", "match1", "(", "url", ",", "r'm\\.miaopai\\.com/show/channel/([^.]+)'", ")", "elif", "'xiaokaxiu.com'", "in", "hostname", ":", "#Xiaokaxiu", "yixia_download_by_scid", "=", "yixia_xiaokaxiu_download_by_scid", "site_info", "=", "\"Yixia Xiaokaxiu\"", "if", "re", ".", "match", "(", "r'http://v.xiaokaxiu.com/v/.+\\.html'", ",", "url", ")", ":", "#PC", "scid", "=", "match1", "(", "url", ",", "r'http://v.xiaokaxiu.com/v/(.+)\\.html'", ")", "elif", "re", ".", "match", "(", "r'http://m.xiaokaxiu.com/m/.+\\.html'", ",", "url", ")", ":", "#Mobile", "scid", "=", "match1", "(", "url", ",", "r'http://m.xiaokaxiu.com/m/(.+)\\.html'", ")", "else", ":", "pass", "yixia_download_by_scid", "(", "scid", ",", "output_dir", ",", "merge", ",", "info_only", ")"], "docstring": "wrapper", "docstring_tokens": ["wrapper"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/yixia.py#L65-L93", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/veoh.py", "func_name": "veoh_download", "original_string": "def veoh_download(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Get item_id'''\n    if re.match(r'http://www.veoh.com/watch/\\w+', url):\n        item_id = match1(url, r'http://www.veoh.com/watch/(\\w+)')\n    elif re.match(r'http://www.veoh.com/m/watch.php\\?v=\\.*', url):\n        item_id = match1(url, r'http://www.veoh.com/m/watch.php\\?v=(\\w+)')\n    else:\n        raise NotImplementedError('Cannot find item ID')\n    veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = info_only, **kwargs)", "language": "python", "code": "def veoh_download(url, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Get item_id'''\n    if re.match(r'http://www.veoh.com/watch/\\w+', url):\n        item_id = match1(url, r'http://www.veoh.com/watch/(\\w+)')\n    elif re.match(r'http://www.veoh.com/m/watch.php\\?v=\\.*', url):\n        item_id = match1(url, r'http://www.veoh.com/m/watch.php\\?v=(\\w+)')\n    else:\n        raise NotImplementedError('Cannot find item ID')\n    veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = info_only, **kwargs)", "code_tokens": ["def", "veoh_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "if", "re", ".", "match", "(", "r'http://www.veoh.com/watch/\\w+'", ",", "url", ")", ":", "item_id", "=", "match1", "(", "url", ",", "r'http://www.veoh.com/watch/(\\w+)'", ")", "elif", "re", ".", "match", "(", "r'http://www.veoh.com/m/watch.php\\?v=\\.*'", ",", "url", ")", ":", "item_id", "=", "match1", "(", "url", ",", "r'http://www.veoh.com/m/watch.php\\?v=(\\w+)'", ")", "else", ":", "raise", "NotImplementedError", "(", "'Cannot find item ID'", ")", "veoh_download_by_id", "(", "item_id", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "info_only", ",", "*", "*", "kwargs", ")"], "docstring": "Get item_id", "docstring_tokens": ["Get", "item_id"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/veoh.py#L8-L16", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/veoh.py", "func_name": "veoh_download_by_id", "original_string": "def veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    \"\"\"Source: Android mobile\"\"\"\n    webpage_url = 'http://www.veoh.com/m/watch.php?v={item_id}&quality=1'.format(item_id = item_id)\n\n    #grab download URL\n    a = get_content(webpage_url, decoded=True)\n    url = match1(a, r'<source src=\"(.*?)\\\"\\W')\n\n    #grab title\n    title = match1(a, r'<meta property=\"og:title\" content=\"([^\"]*)\"')\n\n    type_, ext, size = url_info(url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)", "language": "python", "code": "def veoh_download_by_id(item_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    \"\"\"Source: Android mobile\"\"\"\n    webpage_url = 'http://www.veoh.com/m/watch.php?v={item_id}&quality=1'.format(item_id = item_id)\n\n    #grab download URL\n    a = get_content(webpage_url, decoded=True)\n    url = match1(a, r'<source src=\"(.*?)\\\"\\W')\n\n    #grab title\n    title = match1(a, r'<meta property=\"og:title\" content=\"([^\"]*)\"')\n\n    type_, ext, size = url_info(url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)", "code_tokens": ["def", "veoh_download_by_id", "(", "item_id", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "webpage_url", "=", "'http://www.veoh.com/m/watch.php?v={item_id}&quality=1'", ".", "format", "(", "item_id", "=", "item_id", ")", "#grab download URL", "a", "=", "get_content", "(", "webpage_url", ",", "decoded", "=", "True", ")", "url", "=", "match1", "(", "a", ",", "r'<source src=\"(.*?)\\\"\\W'", ")", "#grab title", "title", "=", "match1", "(", "a", ",", "r'<meta property=\"og:title\" content=\"([^\"]*)\"'", ")", "type_", ",", "ext", ",", "size", "=", "url_info", "(", "url", ")", "print_info", "(", "site_info", ",", "title", ",", "type_", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "[", "url", "]", ",", "title", ",", "ext", ",", "total_size", "=", "None", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "Source: Android mobile", "docstring_tokens": ["Source", ":", "Android", "mobile"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/veoh.py#L19-L33", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/bokecc.py", "func_name": "BokeCC.download_by_id", "original_string": "def download_by_id(self, vid = '', title = None, output_dir='.', merge=True, info_only=False,**kwargs):\n        \"\"\"self, str->None\n        \n        Keyword arguments:\n        self: self\n        vid: The video ID for BokeCC cloud, something like\n        FE3BB999594978049C33DC5901307461\n        \n        Calls the prepare() to download the video.\n        \n        If no title is provided, this method shall try to find a proper title\n        with the information providin within the\n        returned content of the API.\"\"\"\n\n        assert vid\n\n        self.prepare(vid = vid, title = title, **kwargs)\n\n        self.extract(**kwargs)\n\n        self.download(output_dir = output_dir, \n                    merge = merge, \n                    info_only = info_only, **kwargs)", "language": "python", "code": "def download_by_id(self, vid = '', title = None, output_dir='.', merge=True, info_only=False,**kwargs):\n        \"\"\"self, str->None\n        \n        Keyword arguments:\n        self: self\n        vid: The video ID for BokeCC cloud, something like\n        FE3BB999594978049C33DC5901307461\n        \n        Calls the prepare() to download the video.\n        \n        If no title is provided, this method shall try to find a proper title\n        with the information providin within the\n        returned content of the API.\"\"\"\n\n        assert vid\n\n        self.prepare(vid = vid, title = title, **kwargs)\n\n        self.extract(**kwargs)\n\n        self.download(output_dir = output_dir, \n                    merge = merge, \n                    info_only = info_only, **kwargs)", "code_tokens": ["def", "download_by_id", "(", "self", ",", "vid", "=", "''", ",", "title", "=", "None", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "assert", "vid", "self", ".", "prepare", "(", "vid", "=", "vid", ",", "title", "=", "title", ",", "*", "*", "kwargs", ")", "self", ".", "extract", "(", "*", "*", "kwargs", ")", "self", ".", "download", "(", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ",", "*", "*", "kwargs", ")"], "docstring": "self, str->None\n        \n        Keyword arguments:\n        self: self\n        vid: The video ID for BokeCC cloud, something like\n        FE3BB999594978049C33DC5901307461\n        \n        Calls the prepare() to download the video.\n        \n        If no title is provided, this method shall try to find a proper title\n        with the information providin within the\n        returned content of the API.", "docstring_tokens": ["self", "str", "-", ">", "None", "Keyword", "arguments", ":", "self", ":", "self", "vid", ":", "The", "video", "ID", "for", "BokeCC", "cloud", "something", "like", "FE3BB999594978049C33DC5901307461", "Calls", "the", "prepare", "()", "to", "download", "the", "video", ".", "If", "no", "title", "is", "provided", "this", "method", "shall", "try", "to", "find", "a", "proper", "title", "with", "the", "information", "providin", "within", "the", "returned", "content", "of", "the", "API", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/bokecc.py#L17-L39", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/qie.py", "func_name": "QiE.get_vid_from_url", "original_string": "def get_vid_from_url(self, url):\n        \"\"\"Extracts video ID from live.qq.com.\n        \"\"\"\n        hit = re.search(r'live.qq.com/(\\d+)', url)\n        if hit is not None:\n            return hit.group(1)\n        hit = re.search(r'live.qq.com/directory/match/(\\d+)', url)\n        if hit is not None:\n            return self.get_room_id_from_url(hit.group(1))\n        html = get_content(url)\n        room_id = match1(html, r'room_id\\\":(\\d+)')\n        if room_id is None:\n            log.wtf('Unknown page {}'.format(url))\n        return room_id", "language": "python", "code": "def get_vid_from_url(self, url):\n        \"\"\"Extracts video ID from live.qq.com.\n        \"\"\"\n        hit = re.search(r'live.qq.com/(\\d+)', url)\n        if hit is not None:\n            return hit.group(1)\n        hit = re.search(r'live.qq.com/directory/match/(\\d+)', url)\n        if hit is not None:\n            return self.get_room_id_from_url(hit.group(1))\n        html = get_content(url)\n        room_id = match1(html, r'room_id\\\":(\\d+)')\n        if room_id is None:\n            log.wtf('Unknown page {}'.format(url))\n        return room_id", "code_tokens": ["def", "get_vid_from_url", "(", "self", ",", "url", ")", ":", "hit", "=", "re", ".", "search", "(", "r'live.qq.com/(\\d+)'", ",", "url", ")", "if", "hit", "is", "not", "None", ":", "return", "hit", ".", "group", "(", "1", ")", "hit", "=", "re", ".", "search", "(", "r'live.qq.com/directory/match/(\\d+)'", ",", "url", ")", "if", "hit", "is", "not", "None", ":", "return", "self", ".", "get_room_id_from_url", "(", "hit", ".", "group", "(", "1", ")", ")", "html", "=", "get_content", "(", "url", ")", "room_id", "=", "match1", "(", "html", ",", "r'room_id\\\":(\\d+)'", ")", "if", "room_id", "is", "None", ":", "log", ".", "wtf", "(", "'Unknown page {}'", ".", "format", "(", "url", ")", ")", "return", "room_id"], "docstring": "Extracts video ID from live.qq.com.", "docstring_tokens": ["Extracts", "video", "ID", "from", "live", ".", "qq", ".", "com", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/qie.py#L35-L48", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/log.py", "func_name": "sprint", "original_string": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text", "language": "python", "code": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text", "code_tokens": ["def", "sprint", "(", "text", ",", "*", "colors", ")", ":", "return", "\"\\33[{}m{content}\\33[{}m\"", ".", "format", "(", "\";\"", ".", "join", "(", "[", "str", "(", "color", ")", "for", "color", "in", "colors", "]", ")", ",", "RESET", ",", "content", "=", "text", ")", "if", "IS_ANSI_TERMINAL", "and", "colors", "else", "text"], "docstring": "Format text with color or other effects into ANSI escaped string.", "docstring_tokens": ["Format", "text", "with", "color", "or", "other", "effects", "into", "ANSI", "escaped", "string", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L60-L62", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/log.py", "func_name": "print_log", "original_string": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")", "language": "python", "code": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")", "code_tokens": ["def", "print_log", "(", "text", ",", "*", "colors", ")", ":", "sys", ".", "stderr", ".", "write", "(", "sprint", "(", "\"{}: {}\"", ".", "format", "(", "script_name", ",", "text", ")", ",", "*", "colors", ")", "+", "\"\\n\"", ")"], "docstring": "Print a log message to standard error.", "docstring_tokens": ["Print", "a", "log", "message", "to", "standard", "error", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L72-L74", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/log.py", "func_name": "e", "original_string": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)", "language": "python", "code": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)", "code_tokens": ["def", "e", "(", "message", ",", "exit_code", "=", "None", ")", ":", "print_log", "(", "message", ",", "YELLOW", ",", "BOLD", ")", "if", "exit_code", "is", "not", "None", ":", "sys", ".", "exit", "(", "exit_code", ")"], "docstring": "Print an error log message.", "docstring_tokens": ["Print", "an", "error", "log", "message", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L88-L92", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/log.py", "func_name": "wtf", "original_string": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)", "language": "python", "code": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)", "code_tokens": ["def", "wtf", "(", "message", ",", "exit_code", "=", "1", ")", ":", "print_log", "(", "message", ",", "RED", ",", "BOLD", ")", "if", "exit_code", "is", "not", "None", ":", "sys", ".", "exit", "(", "exit_code", ")"], "docstring": "What a Terrible Failure!", "docstring_tokens": ["What", "a", "Terrible", "Failure!"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L94-L98", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/os.py", "func_name": "detect_os", "original_string": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os", "language": "python", "code": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os", "code_tokens": ["def", "detect_os", "(", ")", ":", "# Inspired by:", "# https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py", "syst", "=", "system", "(", ")", ".", "lower", "(", ")", "os", "=", "'unknown'", "if", "'cygwin'", "in", "syst", ":", "os", "=", "'cygwin'", "elif", "'darwin'", "in", "syst", ":", "os", "=", "'mac'", "elif", "'linux'", "in", "syst", ":", "os", "=", "'linux'", "# detect WSL https://github.com/Microsoft/BashOnWindows/issues/423", "try", ":", "with", "open", "(", "'/proc/version'", ",", "'r'", ")", "as", "f", ":", "if", "'microsoft'", "in", "f", ".", "read", "(", ")", ".", "lower", "(", ")", ":", "os", "=", "'wsl'", "except", ":", "pass", "elif", "'windows'", "in", "syst", ":", "os", "=", "'windows'", "elif", "'bsd'", "in", "syst", ":", "os", "=", "'bsd'", "return", "os"], "docstring": "Detect operating system.", "docstring_tokens": ["Detect", "operating", "system", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/os.py#L5-L32", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/miaopai.py", "func_name": "miaopai_download_by_fid", "original_string": "def miaopai_download_by_fid(fid, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    page_url = 'http://video.weibo.com/show?fid=' + fid + '&type=mp4'\n\n    mobile_page = get_content(page_url, headers=fake_headers_mobile)\n    url = match1(mobile_page, r'<video id=.*?src=[\\'\"](.*?)[\\'\"]\\W')\n    if url is None:\n        wb_mp = re.search(r'<script src=([\\'\"])(.+?wb_mp\\.js)\\1>', mobile_page).group(2)\n        return miaopai_download_by_wbmp(wb_mp, fid, output_dir=output_dir, merge=merge,\n                                        info_only=info_only, total_size=None, **kwargs)\n    title = match1(mobile_page, r'<title>((.|\\n)+?)</title>')\n    if not title:\n        title = fid\n    title = title.replace('\\n', '_')\n    ext, size = 'mp4', url_info(url)[2]\n    print_info(site_info, title, ext, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)", "language": "python", "code": "def miaopai_download_by_fid(fid, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    page_url = 'http://video.weibo.com/show?fid=' + fid + '&type=mp4'\n\n    mobile_page = get_content(page_url, headers=fake_headers_mobile)\n    url = match1(mobile_page, r'<video id=.*?src=[\\'\"](.*?)[\\'\"]\\W')\n    if url is None:\n        wb_mp = re.search(r'<script src=([\\'\"])(.+?wb_mp\\.js)\\1>', mobile_page).group(2)\n        return miaopai_download_by_wbmp(wb_mp, fid, output_dir=output_dir, merge=merge,\n                                        info_only=info_only, total_size=None, **kwargs)\n    title = match1(mobile_page, r'<title>((.|\\n)+?)</title>')\n    if not title:\n        title = fid\n    title = title.replace('\\n', '_')\n    ext, size = 'mp4', url_info(url)[2]\n    print_info(site_info, title, ext, size)\n    if not info_only:\n        download_urls([url], title, ext, total_size=None, output_dir=output_dir, merge=merge)", "code_tokens": ["def", "miaopai_download_by_fid", "(", "fid", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "page_url", "=", "'http://video.weibo.com/show?fid='", "+", "fid", "+", "'&type=mp4'", "mobile_page", "=", "get_content", "(", "page_url", ",", "headers", "=", "fake_headers_mobile", ")", "url", "=", "match1", "(", "mobile_page", ",", "r'<video id=.*?src=[\\'\"](.*?)[\\'\"]\\W'", ")", "if", "url", "is", "None", ":", "wb_mp", "=", "re", ".", "search", "(", "r'<script src=([\\'\"])(.+?wb_mp\\.js)\\1>'", ",", "mobile_page", ")", ".", "group", "(", "2", ")", "return", "miaopai_download_by_wbmp", "(", "wb_mp", ",", "fid", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ",", "total_size", "=", "None", ",", "*", "*", "kwargs", ")", "title", "=", "match1", "(", "mobile_page", ",", "r'<title>((.|\\n)+?)</title>'", ")", "if", "not", "title", ":", "title", "=", "fid", "title", "=", "title", ".", "replace", "(", "'\\n'", ",", "'_'", ")", "ext", ",", "size", "=", "'mp4'", ",", "url_info", "(", "url", ")", "[", "2", "]", "print_info", "(", "site_info", ",", "title", ",", "ext", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "[", "url", "]", ",", "title", ",", "ext", ",", "total_size", "=", "None", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")"], "docstring": "Source: Android mobile", "docstring_tokens": ["Source", ":", "Android", "mobile"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miaopai.py#L20-L37", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/vimeo.py", "func_name": "vimeo_download_by_channel", "original_string": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)", "language": "python", "code": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)", "code_tokens": ["def", "vimeo_download_by_channel", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "# https://vimeo.com/channels/464686", "channel_id", "=", "match1", "(", "url", ",", "r'http://vimeo.com/channels/(\\w+)'", ")", "vimeo_download_by_channel_id", "(", "channel_id", ",", "output_dir", ",", "merge", ",", "info_only", ",", "*", "*", "kwargs", ")"], "docstring": "str->None", "docstring_tokens": ["str", "-", ">", "None"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/vimeo.py#L15-L19", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/vimeo.py", "func_name": "vimeo_download_by_channel_id", "original_string": "def vimeo_download_by_channel_id(channel_id, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str/int->None\"\"\"\n    html = get_content('https://api.vimeo.com/channels/{channel_id}/videos?access_token={access_token}'.format(channel_id=channel_id, access_token=access_token))\n    data = loads(html)\n    id_list = []\n\n    #print(data)\n    for i in data['data']:\n        id_list.append(match1(i['uri'], r'/videos/(\\w+)'))\n\n    for id in id_list:\n        try:\n            vimeo_download_by_id(id, None, output_dir, merge, info_only, **kwargs)\n        except urllib.error.URLError as e:\n            log.w('{} failed with {}'.format(id, e))", "language": "python", "code": "def vimeo_download_by_channel_id(channel_id, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str/int->None\"\"\"\n    html = get_content('https://api.vimeo.com/channels/{channel_id}/videos?access_token={access_token}'.format(channel_id=channel_id, access_token=access_token))\n    data = loads(html)\n    id_list = []\n\n    #print(data)\n    for i in data['data']:\n        id_list.append(match1(i['uri'], r'/videos/(\\w+)'))\n\n    for id in id_list:\n        try:\n            vimeo_download_by_id(id, None, output_dir, merge, info_only, **kwargs)\n        except urllib.error.URLError as e:\n            log.w('{} failed with {}'.format(id, e))", "code_tokens": ["def", "vimeo_download_by_channel_id", "(", "channel_id", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "html", "=", "get_content", "(", "'https://api.vimeo.com/channels/{channel_id}/videos?access_token={access_token}'", ".", "format", "(", "channel_id", "=", "channel_id", ",", "access_token", "=", "access_token", ")", ")", "data", "=", "loads", "(", "html", ")", "id_list", "=", "[", "]", "#print(data)", "for", "i", "in", "data", "[", "'data'", "]", ":", "id_list", ".", "append", "(", "match1", "(", "i", "[", "'uri'", "]", ",", "r'/videos/(\\w+)'", ")", ")", "for", "id", "in", "id_list", ":", "try", ":", "vimeo_download_by_id", "(", "id", ",", "None", ",", "output_dir", ",", "merge", ",", "info_only", ",", "*", "*", "kwargs", ")", "except", "urllib", ".", "error", ".", "URLError", "as", "e", ":", "log", ".", "w", "(", "'{} failed with {}'", ".", "format", "(", "id", ",", "e", ")", ")"], "docstring": "str/int->None", "docstring_tokens": ["str", "/", "int", "-", ">", "None"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/vimeo.py#L22-L36", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/vimeo.py", "func_name": "vimeo_download_by_id", "original_string": "def vimeo_download_by_id(id, title=None, output_dir='.', merge=True, info_only=False, **kwargs):\n    '''\n    try:\n        # normal Vimeo video\n        html = get_content('https://vimeo.com/' + id)\n        cfg_patt = r'clip_page_config\\s*=\\s*(\\{.+?\\});'\n        cfg = json.loads(match1(html, cfg_patt))\n        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)\n        title = cfg['clip']['title']\n        info = loads(video_page)\n    except:\n        # embedded player - referer may be required\n        if 'referer' in kwargs:\n            fake_headers['Referer'] = kwargs['referer']\n\n        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)\n        title = r1(r'<title>([^<]+)</title>', video_page)\n        info = loads(match1(video_page, r'var t=(\\{.+?\\});'))\n\n    streams = info['request']['files']['progressive']\n    streams = sorted(streams, key=lambda i: i['height'])\n    url = streams[-1]['url']\n\n    type, ext, size = url_info(url, faker=True)\n\n    print_info(site_info, title, type, size)\n    if not info_only:\n        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True)\n    '''\n    site = VimeoExtractor()\n    site.download_by_vid(id, info_only=info_only, output_dir=output_dir, merge=merge, **kwargs)", "language": "python", "code": "def vimeo_download_by_id(id, title=None, output_dir='.', merge=True, info_only=False, **kwargs):\n    '''\n    try:\n        # normal Vimeo video\n        html = get_content('https://vimeo.com/' + id)\n        cfg_patt = r'clip_page_config\\s*=\\s*(\\{.+?\\});'\n        cfg = json.loads(match1(html, cfg_patt))\n        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)\n        title = cfg['clip']['title']\n        info = loads(video_page)\n    except:\n        # embedded player - referer may be required\n        if 'referer' in kwargs:\n            fake_headers['Referer'] = kwargs['referer']\n\n        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)\n        title = r1(r'<title>([^<]+)</title>', video_page)\n        info = loads(match1(video_page, r'var t=(\\{.+?\\});'))\n\n    streams = info['request']['files']['progressive']\n    streams = sorted(streams, key=lambda i: i['height'])\n    url = streams[-1]['url']\n\n    type, ext, size = url_info(url, faker=True)\n\n    print_info(site_info, title, type, size)\n    if not info_only:\n        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True)\n    '''\n    site = VimeoExtractor()\n    site.download_by_vid(id, info_only=info_only, output_dir=output_dir, merge=merge, **kwargs)", "code_tokens": ["def", "vimeo_download_by_id", "(", "id", ",", "title", "=", "None", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "site", "=", "VimeoExtractor", "(", ")", "site", ".", "download_by_vid", "(", "id", ",", "info_only", "=", "info_only", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "*", "*", "kwargs", ")"], "docstring": "try:\n        # normal Vimeo video\n        html = get_content('https://vimeo.com/' + id)\n        cfg_patt = r'clip_page_config\\s*=\\s*(\\{.+?\\});'\n        cfg = json.loads(match1(html, cfg_patt))\n        video_page = get_content(cfg['player']['config_url'], headers=fake_headers)\n        title = cfg['clip']['title']\n        info = loads(video_page)\n    except:\n        # embedded player - referer may be required\n        if 'referer' in kwargs:\n            fake_headers['Referer'] = kwargs['referer']\n\n        video_page = get_content('http://player.vimeo.com/video/%s' % id, headers=fake_headers)\n        title = r1(r'<title>([^<]+)</title>', video_page)\n        info = loads(match1(video_page, r'var t=(\\{.+?\\});'))\n\n    streams = info['request']['files']['progressive']\n    streams = sorted(streams, key=lambda i: i['height'])\n    url = streams[-1]['url']\n\n    type, ext, size = url_info(url, faker=True)\n\n    print_info(site_info, title, type, size)\n    if not info_only:\n        download_urls([url], title, ext, size, output_dir, merge=merge, faker=True)", "docstring_tokens": ["try", ":", "#", "normal", "Vimeo", "video", "html", "=", "get_content", "(", "https", ":", "//", "vimeo", ".", "com", "/", "+", "id", ")", "cfg_patt", "=", "r", "clip_page_config", "\\", "s", "*", "=", "\\", "s", "*", "(", "\\", "{", ".", "+", "?", "\\", "}", ")", ";", "cfg", "=", "json", ".", "loads", "(", "match1", "(", "html", "cfg_patt", "))", "video_page", "=", "get_content", "(", "cfg", "[", "player", "]", "[", "config_url", "]", "headers", "=", "fake_headers", ")", "title", "=", "cfg", "[", "clip", "]", "[", "title", "]", "info", "=", "loads", "(", "video_page", ")", "except", ":", "#", "embedded", "player", "-", "referer", "may", "be", "required", "if", "referer", "in", "kwargs", ":", "fake_headers", "[", "Referer", "]", "=", "kwargs", "[", "referer", "]"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/vimeo.py#L134-L164", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/ckplayer.py", "func_name": "ckplayer_get_info_by_xml", "original_string": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict", "language": "python", "code": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict", "code_tokens": ["def", "ckplayer_get_info_by_xml", "(", "ckinfo", ")", ":", "e", "=", "ET", ".", "XML", "(", "ckinfo", ")", "video_dict", "=", "{", "'title'", ":", "''", ",", "#'duration': 0,", "'links'", ":", "[", "]", ",", "'size'", ":", "0", ",", "'flashvars'", ":", "''", ",", "}", "dictified", "=", "dictify", "(", "e", ")", "[", "'ckplayer'", "]", "if", "'info'", "in", "dictified", ":", "if", "'_text'", "in", "dictified", "[", "'info'", "]", "[", "0", "]", "[", "'title'", "]", "[", "0", "]", ":", "#title", "video_dict", "[", "'title'", "]", "=", "dictified", "[", "'info'", "]", "[", "0", "]", "[", "'title'", "]", "[", "0", "]", "[", "'_text'", "]", ".", "strip", "(", ")", "#if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration", "#video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()", "if", "'_text'", "in", "dictified", "[", "'video'", "]", "[", "0", "]", "[", "'size'", "]", "[", "0", "]", ":", "#size exists for 1 piece", "video_dict", "[", "'size'", "]", "=", "sum", "(", "[", "int", "(", "i", "[", "'size'", "]", "[", "0", "]", "[", "'_text'", "]", ")", "for", "i", "in", "dictified", "[", "'video'", "]", "]", ")", "if", "'_text'", "in", "dictified", "[", "'video'", "]", "[", "0", "]", "[", "'file'", "]", "[", "0", "]", ":", "#link exist", "video_dict", "[", "'links'", "]", "=", "[", "i", "[", "'file'", "]", "[", "0", "]", "[", "'_text'", "]", ".", "strip", "(", ")", "for", "i", "in", "dictified", "[", "'video'", "]", "]", "if", "'_text'", "in", "dictified", "[", "'flashvars'", "]", "[", "0", "]", ":", "video_dict", "[", "'flashvars'", "]", "=", "dictified", "[", "'flashvars'", "]", "[", "0", "]", "[", "'_text'", "]", ".", "strip", "(", ")", "return", "video_dict"], "docstring": "str->dict\n    Information for CKPlayer API content.", "docstring_tokens": ["str", "-", ">", "dict", "Information", "for", "CKPlayer", "API", "content", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ckplayer.py#L13-L39", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/ixigua.py", "func_name": "get_video_url_from_video_id", "original_string": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url", "language": "python", "code": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url", "code_tokens": ["def", "get_video_url_from_video_id", "(", "video_id", ")", ":", "# from js", "data", "=", "[", "\"\"", "]", "*", "256", "for", "index", ",", "_", "in", "enumerate", "(", "data", ")", ":", "t", "=", "index", "for", "i", "in", "range", "(", "8", ")", ":", "t", "=", "-", "306674912", "^", "unsigned_right_shitf", "(", "t", ",", "1", ")", "if", "1", "&", "t", "else", "unsigned_right_shitf", "(", "t", ",", "1", ")", "data", "[", "index", "]", "=", "t", "def", "tmp", "(", ")", ":", "rand_num", "=", "random", ".", "random", "(", ")", "path", "=", "\"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\"", ".", "format", "(", "video_id", "=", "video_id", ",", "random_num", "=", "str", "(", "rand_num", ")", "[", "2", ":", "]", ")", "e", "=", "o", "=", "r", "=", "-", "1", "i", ",", "a", "=", "0", ",", "len", "(", "path", ")", "while", "i", "<", "a", ":", "e", "=", "ord", "(", "path", "[", "i", "]", ")", "i", "+=", "1", "if", "e", "<", "128", ":", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "e", ")", "]", "else", ":", "if", "e", "<", "2048", ":", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "192", "|", "e", ">>", "6", "&", "31", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "63", "&", "e", ")", ")", "]", "else", ":", "if", "55296", "<=", "e", "<", "57344", ":", "e", "=", "(", "1023", "&", "e", ")", "+", "64", "i", "+=", "1", "o", "=", "1023", "&", "t", ".", "url", "(", "i", ")", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "240", "|", "e", ">>", "8", "&", "7", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "e", ">>", "2", "&", "63", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "o", ">>", "6", "&", "15", "|", "(", "3", "&", "e", ")", "<<", "4", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "63", "&", "o", ")", ")", "]", "else", ":", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "224", "|", "e", ">>", "12", "&", "15", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "e", ">>", "6", "&", "63", ")", ")", "]", "r", "=", "unsigned_right_shitf", "(", "r", ",", "8", ")", "^", "data", "[", "255", "&", "(", "r", "^", "(", "128", "|", "63", "&", "e", ")", ")", "]", "return", "\"https://ib.365yg.com{path}&s={param}\"", ".", "format", "(", "path", "=", "path", ",", "param", "=", "unsigned_right_shitf", "(", "r", "^", "-", "1", ",", "0", ")", ")", "while", "1", ":", "url", "=", "tmp", "(", ")", "if", "url", ".", "split", "(", "\"=\"", ")", "[", "-", "1", "]", "[", "0", "]", "!=", "\"-\"", ":", "# \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570", "return", "url"], "docstring": "Splicing URLs according to video ID to get video details", "docstring_tokens": ["Splicing", "URLs", "according", "to", "video", "ID", "to", "get", "video", "details"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ixigua.py#L34-L78", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/mgtv.py", "func_name": "MGTV.get_vid_from_url", "original_string": "def get_vid_from_url(url):\n        \"\"\"Extracts video ID from URL.\n        \"\"\"\n        vid = match1(url, 'https?://www.mgtv.com/(?:b|l)/\\d+/(\\d+).html')\n        if not vid:\n            vid = match1(url, 'https?://www.mgtv.com/hz/bdpz/\\d+/(\\d+).html')\n        return vid", "language": "python", "code": "def get_vid_from_url(url):\n        \"\"\"Extracts video ID from URL.\n        \"\"\"\n        vid = match1(url, 'https?://www.mgtv.com/(?:b|l)/\\d+/(\\d+).html')\n        if not vid:\n            vid = match1(url, 'https?://www.mgtv.com/hz/bdpz/\\d+/(\\d+).html')\n        return vid", "code_tokens": ["def", "get_vid_from_url", "(", "url", ")", ":", "vid", "=", "match1", "(", "url", ",", "'https?://www.mgtv.com/(?:b|l)/\\d+/(\\d+).html'", ")", "if", "not", "vid", ":", "vid", "=", "match1", "(", "url", ",", "'https?://www.mgtv.com/hz/bdpz/\\d+/(\\d+).html'", ")", "return", "vid"], "docstring": "Extracts video ID from URL.", "docstring_tokens": ["Extracts", "video", "ID", "from", "URL", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/mgtv.py#L27-L33", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/mgtv.py", "func_name": "MGTV.get_mgtv_real_url", "original_string": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list", "language": "python", "code": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list", "code_tokens": ["def", "get_mgtv_real_url", "(", "url", ")", ":", "content", "=", "loads", "(", "get_content", "(", "url", ")", ")", "m3u_url", "=", "content", "[", "'info'", "]", "split", "=", "urlsplit", "(", "m3u_url", ")", "base_url", "=", "\"{scheme}://{netloc}{path}/\"", ".", "format", "(", "scheme", "=", "split", "[", "0", "]", ",", "netloc", "=", "split", "[", "1", "]", ",", "path", "=", "dirname", "(", "split", "[", "2", "]", ")", ")", "content", "=", "get_content", "(", "content", "[", "'info'", "]", ")", "#get the REAL M3U url, maybe to be changed later?", "segment_list", "=", "[", "]", "segments_size", "=", "0", "for", "i", "in", "content", ".", "split", "(", ")", ":", "if", "not", "i", ".", "startswith", "(", "'#'", ")", ":", "#not the best way, better we use the m3u8 package", "segment_list", ".", "append", "(", "base_url", "+", "i", ")", "# use ext-info for fast size calculate", "elif", "i", ".", "startswith", "(", "'#EXT-MGTV-File-SIZE:'", ")", ":", "segments_size", "+=", "int", "(", "i", "[", "i", ".", "rfind", "(", "':'", ")", "+", "1", ":", "]", ")", "return", "m3u_url", ",", "segments_size", ",", "segment_list"], "docstring": "str->list of str\n        Give you the real URLs.", "docstring_tokens": ["str", "-", ">", "list", "of", "str", "Give", "you", "the", "real", "URLs", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/mgtv.py#L37-L58", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/git.py", "func_name": "get_head", "original_string": "def get_head(repo_path):\n    \"\"\"Get (branch, commit) from HEAD of a git repo.\"\"\"\n    try:\n        ref = open(os.path.join(repo_path, '.git', 'HEAD'), 'r').read().strip()[5:].split('/')\n        branch = ref[-1]\n        commit = open(os.path.join(repo_path, '.git', *ref), 'r').read().strip()[:7]\n        return branch, commit\n    except:\n        return None", "language": "python", "code": "def get_head(repo_path):\n    \"\"\"Get (branch, commit) from HEAD of a git repo.\"\"\"\n    try:\n        ref = open(os.path.join(repo_path, '.git', 'HEAD'), 'r').read().strip()[5:].split('/')\n        branch = ref[-1]\n        commit = open(os.path.join(repo_path, '.git', *ref), 'r').read().strip()[:7]\n        return branch, commit\n    except:\n        return None", "code_tokens": ["def", "get_head", "(", "repo_path", ")", ":", "try", ":", "ref", "=", "open", "(", "os", ".", "path", ".", "join", "(", "repo_path", ",", "'.git'", ",", "'HEAD'", ")", ",", "'r'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", "[", "5", ":", "]", ".", "split", "(", "'/'", ")", "branch", "=", "ref", "[", "-", "1", "]", "commit", "=", "open", "(", "os", ".", "path", ".", "join", "(", "repo_path", ",", "'.git'", ",", "*", "ref", ")", ",", "'r'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", "[", ":", "7", "]", "return", "branch", ",", "commit", "except", ":", "return", "None"], "docstring": "Get (branch, commit) from HEAD of a git repo.", "docstring_tokens": ["Get", "(", "branch", "commit", ")", "from", "HEAD", "of", "a", "git", "repo", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/git.py#L7-L15", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/fs.py", "func_name": "legitimize", "original_string": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text", "language": "python", "code": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text", "code_tokens": ["def", "legitimize", "(", "text", ",", "os", "=", "detect_os", "(", ")", ")", ":", "# POSIX systems", "text", "=", "text", ".", "translate", "(", "{", "0", ":", "None", ",", "ord", "(", "'/'", ")", ":", "'-'", ",", "ord", "(", "'|'", ")", ":", "'-'", ",", "}", ")", "# FIXME: do some filesystem detection", "if", "os", "==", "'windows'", "or", "os", "==", "'cygwin'", "or", "os", "==", "'wsl'", ":", "# Windows (non-POSIX namespace)", "text", "=", "text", ".", "translate", "(", "{", "# Reserved in Windows VFAT and NTFS", "ord", "(", "':'", ")", ":", "'-'", ",", "ord", "(", "'*'", ")", ":", "'-'", ",", "ord", "(", "'?'", ")", ":", "'-'", ",", "ord", "(", "'\\\\'", ")", ":", "'-'", ",", "ord", "(", "'\\\"'", ")", ":", "'\\''", ",", "# Reserved in Windows VFAT", "ord", "(", "'+'", ")", ":", "'-'", ",", "ord", "(", "'<'", ")", ":", "'-'", ",", "ord", "(", "'>'", ")", ":", "'-'", ",", "ord", "(", "'['", ")", ":", "'('", ",", "ord", "(", "']'", ")", ":", "')'", ",", "ord", "(", "'\\t'", ")", ":", "' '", ",", "}", ")", "else", ":", "# *nix", "if", "os", "==", "'mac'", ":", "# Mac OS HFS+", "text", "=", "text", ".", "translate", "(", "{", "ord", "(", "':'", ")", ":", "'-'", ",", "}", ")", "# Remove leading .", "if", "text", ".", "startswith", "(", "\".\"", ")", ":", "text", "=", "text", "[", "1", ":", "]", "text", "=", "text", "[", ":", "80", "]", "# Trim to 82 Unicode characters long", "return", "text"], "docstring": "Converts a string to a valid filename.", "docstring_tokens": ["Converts", "a", "string", "to", "a", "valid", "filename", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/fs.py#L5-L47", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/util/term.py", "func_name": "get_terminal_size", "original_string": "def get_terminal_size():\n    \"\"\"Get (width, height) of the current terminal.\"\"\"\n    try:\n        import fcntl, termios, struct # fcntl module only available on Unix\n        return struct.unpack('hh', fcntl.ioctl(1, termios.TIOCGWINSZ, '1234'))\n    except:\n        return (40, 80)", "language": "python", "code": "def get_terminal_size():\n    \"\"\"Get (width, height) of the current terminal.\"\"\"\n    try:\n        import fcntl, termios, struct # fcntl module only available on Unix\n        return struct.unpack('hh', fcntl.ioctl(1, termios.TIOCGWINSZ, '1234'))\n    except:\n        return (40, 80)", "code_tokens": ["def", "get_terminal_size", "(", ")", ":", "try", ":", "import", "fcntl", ",", "termios", ",", "struct", "# fcntl module only available on Unix", "return", "struct", ".", "unpack", "(", "'hh'", ",", "fcntl", ".", "ioctl", "(", "1", ",", "termios", ".", "TIOCGWINSZ", ",", "'1234'", ")", ")", "except", ":", "return", "(", "40", ",", "80", ")"], "docstring": "Get (width, height) of the current terminal.", "docstring_tokens": ["Get", "(", "width", "height", ")", "of", "the", "current", "terminal", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/term.py#L3-L9", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/cbs.py", "func_name": "cbs_download", "original_string": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)", "language": "python", "code": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)", "code_tokens": ["def", "cbs_download", "(", "url", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "html", "=", "get_content", "(", "url", ")", "pid", "=", "match1", "(", "html", ",", "r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\''", ")", "title", "=", "match1", "(", "html", ",", "r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"'", ")", "theplatform_download_by_pid", "(", "pid", ",", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")"], "docstring": "Downloads CBS videos by URL.", "docstring_tokens": ["Downloads", "CBS", "videos", "by", "URL", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/cbs.py#L9-L17", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/iqiyi.py", "func_name": "Iqiyi.download", "original_string": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')", "language": "python", "code": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')", "code_tokens": ["def", "download", "(", "self", ",", "*", "*", "kwargs", ")", ":", "if", "'json_output'", "in", "kwargs", "and", "kwargs", "[", "'json_output'", "]", ":", "json_output", ".", "output", "(", "self", ")", "elif", "'info_only'", "in", "kwargs", "and", "kwargs", "[", "'info_only'", "]", ":", "if", "'stream_id'", "in", "kwargs", "and", "kwargs", "[", "'stream_id'", "]", ":", "# Display the stream", "stream_id", "=", "kwargs", "[", "'stream_id'", "]", "if", "'index'", "not", "in", "kwargs", ":", "self", ".", "p", "(", "stream_id", ")", "else", ":", "self", ".", "p_i", "(", "stream_id", ")", "else", ":", "# Display all available streams", "if", "'index'", "not", "in", "kwargs", ":", "self", ".", "p", "(", "[", "]", ")", "else", ":", "stream_id", "=", "self", ".", "streams_sorted", "[", "0", "]", "[", "'id'", "]", "if", "'id'", "in", "self", ".", "streams_sorted", "[", "0", "]", "else", "self", ".", "streams_sorted", "[", "0", "]", "[", "'itag'", "]", "self", ".", "p_i", "(", "stream_id", ")", "else", ":", "if", "'stream_id'", "in", "kwargs", "and", "kwargs", "[", "'stream_id'", "]", ":", "# Download the stream", "stream_id", "=", "kwargs", "[", "'stream_id'", "]", "else", ":", "# Download stream with the best quality", "stream_id", "=", "self", ".", "streams_sorted", "[", "0", "]", "[", "'id'", "]", "if", "'id'", "in", "self", ".", "streams_sorted", "[", "0", "]", "else", "self", ".", "streams_sorted", "[", "0", "]", "[", "'itag'", "]", "if", "'index'", "not", "in", "kwargs", ":", "self", ".", "p", "(", "stream_id", ")", "else", ":", "self", ".", "p_i", "(", "stream_id", ")", "if", "stream_id", "in", "self", ".", "streams", ":", "urls", "=", "self", ".", "streams", "[", "stream_id", "]", "[", "'src'", "]", "ext", "=", "self", ".", "streams", "[", "stream_id", "]", "[", "'container'", "]", "total_size", "=", "self", ".", "streams", "[", "stream_id", "]", "[", "'size'", "]", "else", ":", "urls", "=", "self", ".", "dash_streams", "[", "stream_id", "]", "[", "'src'", "]", "ext", "=", "self", ".", "dash_streams", "[", "stream_id", "]", "[", "'container'", "]", "total_size", "=", "self", ".", "dash_streams", "[", "stream_id", "]", "[", "'size'", "]", "if", "not", "urls", ":", "log", ".", "wtf", "(", "'[Failed] Cannot extract video source.'", ")", "# For legacy main()", "#Here's the change!!", "download_url_ffmpeg", "(", "urls", "[", "0", "]", ",", "self", ".", "title", ",", "'mp4'", ",", "output_dir", "=", "kwargs", "[", "'output_dir'", "]", ",", "merge", "=", "kwargs", "[", "'merge'", "]", ",", "stream", "=", "False", ")", "if", "not", "kwargs", "[", "'caption'", "]", ":", "print", "(", "'Skipping captions.'", ")", "return", "for", "lang", "in", "self", ".", "caption_tracks", ":", "filename", "=", "'%s.%s.srt'", "%", "(", "get_filename", "(", "self", ".", "title", ")", ",", "lang", ")", "print", "(", "'Saving %s ... '", "%", "filename", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "srt", "=", "self", ".", "caption_tracks", "[", "lang", "]", "with", "open", "(", "os", ".", "path", ".", "join", "(", "kwargs", "[", "'output_dir'", "]", ",", "filename", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "x", ":", "x", ".", "write", "(", "srt", ")", "print", "(", "'Done.'", ")"], "docstring": "Override the original one\n        Ugly ugly dirty hack", "docstring_tokens": ["Override", "the", "original", "one", "Ugly", "ugly", "dirty", "hack"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/iqiyi.py#L158-L218", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/acfun.py", "func_name": "acfun_download_by_vid", "original_string": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass", "language": "python", "code": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass", "code_tokens": ["def", "acfun_download_by_vid", "(", "vid", ",", "title", ",", "output_dir", "=", "'.'", ",", "merge", "=", "True", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "#first call the main parasing API", "info", "=", "json", ".", "loads", "(", "get_content", "(", "'http://www.acfun.cn/video/getVideo.aspx?id='", "+", "vid", ")", ")", "sourceType", "=", "info", "[", "'sourceType'", "]", "#decide sourceId to know which extractor to use", "if", "'sourceId'", "in", "info", ":", "sourceId", "=", "info", "[", "'sourceId'", "]", "# danmakuId = info['danmakuId']", "#call extractor decided by sourceId", "if", "sourceType", "==", "'sina'", ":", "sina_download_by_vid", "(", "sourceId", ",", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "elif", "sourceType", "==", "'youku'", ":", "youku_download_by_vid", "(", "sourceId", ",", "title", "=", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ",", "*", "*", "kwargs", ")", "elif", "sourceType", "==", "'tudou'", ":", "tudou_download_by_iid", "(", "sourceId", ",", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "elif", "sourceType", "==", "'qq'", ":", "qq_download_by_vid", "(", "sourceId", ",", "title", ",", "True", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "elif", "sourceType", "==", "'letv'", ":", "letvcloud_download_by_vu", "(", "sourceId", ",", "'2d8c027396'", ",", "title", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ",", "info_only", "=", "info_only", ")", "elif", "sourceType", "==", "'zhuzhan'", ":", "#As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this", "#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player", "#old code removed", "url", "=", "'http://www.acfun.cn/v/ac'", "+", "vid", "yk_streams", "=", "youku_acfun_proxy", "(", "info", "[", "'sourceId'", "]", ",", "info", "[", "'encode'", "]", ",", "url", ")", "seq", "=", "[", "'mp4hd3'", ",", "'mp4hd2'", ",", "'mp4hd'", ",", "'flvhd'", "]", "for", "t", "in", "seq", ":", "if", "yk_streams", ".", "get", "(", "t", ")", ":", "preferred", "=", "yk_streams", "[", "t", "]", "break", "#total_size in the json could be incorrect(F.I. 0)", "size", "=", "0", "for", "url", "in", "preferred", "[", "0", "]", ":", "_", ",", "_", ",", "seg_size", "=", "url_info", "(", "url", ")", "size", "+=", "seg_size", "#fallback to flvhd is not quite possible", "if", "re", ".", "search", "(", "r'fid=[0-9A-Z\\-]*.flv'", ",", "preferred", "[", "0", "]", "[", "0", "]", ")", ":", "ext", "=", "'flv'", "else", ":", "ext", "=", "'mp4'", "print_info", "(", "site_info", ",", "title", ",", "ext", ",", "size", ")", "if", "not", "info_only", ":", "download_urls", "(", "preferred", "[", "0", "]", ",", "title", ",", "ext", ",", "size", ",", "output_dir", "=", "output_dir", ",", "merge", "=", "merge", ")", "else", ":", "raise", "NotImplementedError", "(", "sourceType", ")", "if", "not", "info_only", "and", "not", "dry_run", ":", "if", "not", "kwargs", "[", "'caption'", "]", ":", "print", "(", "'Skipping danmaku.'", ")", "return", "try", ":", "title", "=", "get_filename", "(", "title", ")", "print", "(", "'Downloading %s ...\\n'", "%", "(", "title", "+", "'.cmt.json'", ")", ")", "cmt", "=", "get_srt_json", "(", "vid", ")", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "title", "+", "'.cmt.json'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "x", ":", "x", ".", "write", "(", "cmt", ")", "except", ":", "pass"], "docstring": "str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.", "docstring_tokens": ["str", "str", "str", "bool", "bool", "-", ">", "None"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/acfun.py#L42-L109", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/__main__.py", "func_name": "main_dev", "original_string": "def main_dev(**kwargs):\n    \"\"\"Main entry point.\n    you-get-dev\n    \"\"\"\n\n    # Get (branch, commit) if running from a git repo.\n    head = git.get_head(kwargs['repo_path'])\n\n    # Get options and arguments.\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], _short_options, _options)\n    except getopt.GetoptError as e:\n        log.wtf(\"\"\"\n    [Fatal] {}.\n    Try '{} --help' for more options.\"\"\".format(e, script_name))\n\n    if not opts and not args:\n        # Display help.\n        print(_help)\n        # Enter GUI mode.\n        #from .gui import gui_main\n        #gui_main()\n    else:\n        conf = {}\n        for opt, arg in opts:\n            if opt in ('-h', '--help'):\n                # Display help.\n                print(_help)\n\n            elif opt in ('-V', '--version'):\n                # Display version.\n                log.println(\"you-get:\", log.BOLD)\n                log.println(\"    version:  {}\".format(__version__))\n                if head is not None:\n                    log.println(\"    branch:   {}\\n    commit:   {}\".format(*head))\n                else:\n                    log.println(\"    branch:   {}\\n    commit:   {}\".format(\"(stable)\", \"(tag v{})\".format(__version__)))\n\n                log.println(\"    platform: {}\".format(platform.platform()))\n                log.println(\"    python:   {}\".format(sys.version.split('\\n')[0]))\n\n            elif opt in ('-g', '--gui'):\n                # Run using GUI.\n                conf['gui'] = True\n\n            elif opt in ('-f', '--force'):\n                # Force download.\n                conf['force'] = True\n\n            elif opt in ('-l', '--playlist', '--playlists'):\n                # Download playlist whenever possible.\n                conf['playlist'] = True\n\n        if args:\n            if 'gui' in conf and conf['gui']:\n                # Enter GUI mode.\n                from .gui import gui_main\n                gui_main(*args, **conf)\n            else:\n                # Enter console mode.\n                from .console import console_main\n                console_main(*args, **conf)", "language": "python", "code": "def main_dev(**kwargs):\n    \"\"\"Main entry point.\n    you-get-dev\n    \"\"\"\n\n    # Get (branch, commit) if running from a git repo.\n    head = git.get_head(kwargs['repo_path'])\n\n    # Get options and arguments.\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], _short_options, _options)\n    except getopt.GetoptError as e:\n        log.wtf(\"\"\"\n    [Fatal] {}.\n    Try '{} --help' for more options.\"\"\".format(e, script_name))\n\n    if not opts and not args:\n        # Display help.\n        print(_help)\n        # Enter GUI mode.\n        #from .gui import gui_main\n        #gui_main()\n    else:\n        conf = {}\n        for opt, arg in opts:\n            if opt in ('-h', '--help'):\n                # Display help.\n                print(_help)\n\n            elif opt in ('-V', '--version'):\n                # Display version.\n                log.println(\"you-get:\", log.BOLD)\n                log.println(\"    version:  {}\".format(__version__))\n                if head is not None:\n                    log.println(\"    branch:   {}\\n    commit:   {}\".format(*head))\n                else:\n                    log.println(\"    branch:   {}\\n    commit:   {}\".format(\"(stable)\", \"(tag v{})\".format(__version__)))\n\n                log.println(\"    platform: {}\".format(platform.platform()))\n                log.println(\"    python:   {}\".format(sys.version.split('\\n')[0]))\n\n            elif opt in ('-g', '--gui'):\n                # Run using GUI.\n                conf['gui'] = True\n\n            elif opt in ('-f', '--force'):\n                # Force download.\n                conf['force'] = True\n\n            elif opt in ('-l', '--playlist', '--playlists'):\n                # Download playlist whenever possible.\n                conf['playlist'] = True\n\n        if args:\n            if 'gui' in conf and conf['gui']:\n                # Enter GUI mode.\n                from .gui import gui_main\n                gui_main(*args, **conf)\n            else:\n                # Enter console mode.\n                from .console import console_main\n                console_main(*args, **conf)", "code_tokens": ["def", "main_dev", "(", "*", "*", "kwargs", ")", ":", "# Get (branch, commit) if running from a git repo.", "head", "=", "git", ".", "get_head", "(", "kwargs", "[", "'repo_path'", "]", ")", "# Get options and arguments.", "try", ":", "opts", ",", "args", "=", "getopt", ".", "getopt", "(", "sys", ".", "argv", "[", "1", ":", "]", ",", "_short_options", ",", "_options", ")", "except", "getopt", ".", "GetoptError", "as", "e", ":", "log", ".", "wtf", "(", "\"\"\"\n    [Fatal] {}.\n    Try '{} --help' for more options.\"\"\"", ".", "format", "(", "e", ",", "script_name", ")", ")", "if", "not", "opts", "and", "not", "args", ":", "# Display help.", "print", "(", "_help", ")", "# Enter GUI mode.", "#from .gui import gui_main", "#gui_main()", "else", ":", "conf", "=", "{", "}", "for", "opt", ",", "arg", "in", "opts", ":", "if", "opt", "in", "(", "'-h'", ",", "'--help'", ")", ":", "# Display help.", "print", "(", "_help", ")", "elif", "opt", "in", "(", "'-V'", ",", "'--version'", ")", ":", "# Display version.", "log", ".", "println", "(", "\"you-get:\"", ",", "log", ".", "BOLD", ")", "log", ".", "println", "(", "\"    version:  {}\"", ".", "format", "(", "__version__", ")", ")", "if", "head", "is", "not", "None", ":", "log", ".", "println", "(", "\"    branch:   {}\\n    commit:   {}\"", ".", "format", "(", "*", "head", ")", ")", "else", ":", "log", ".", "println", "(", "\"    branch:   {}\\n    commit:   {}\"", ".", "format", "(", "\"(stable)\"", ",", "\"(tag v{})\"", ".", "format", "(", "__version__", ")", ")", ")", "log", ".", "println", "(", "\"    platform: {}\"", ".", "format", "(", "platform", ".", "platform", "(", ")", ")", ")", "log", ".", "println", "(", "\"    python:   {}\"", ".", "format", "(", "sys", ".", "version", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ")", ")", "elif", "opt", "in", "(", "'-g'", ",", "'--gui'", ")", ":", "# Run using GUI.", "conf", "[", "'gui'", "]", "=", "True", "elif", "opt", "in", "(", "'-f'", ",", "'--force'", ")", ":", "# Force download.", "conf", "[", "'force'", "]", "=", "True", "elif", "opt", "in", "(", "'-l'", ",", "'--playlist'", ",", "'--playlists'", ")", ":", "# Download playlist whenever possible.", "conf", "[", "'playlist'", "]", "=", "True", "if", "args", ":", "if", "'gui'", "in", "conf", "and", "conf", "[", "'gui'", "]", ":", "# Enter GUI mode.", "from", ".", "gui", "import", "gui_main", "gui_main", "(", "*", "args", ",", "*", "*", "conf", ")", "else", ":", "# Enter console mode.", "from", ".", "console", "import", "console_main", "console_main", "(", "*", "args", ",", "*", "*", "conf", ")"], "docstring": "Main entry point.\n    you-get-dev", "docstring_tokens": ["Main", "entry", "point", ".", "you", "-", "get", "-", "dev"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/__main__.py#L24-L85", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/processor/ffmpeg.py", "func_name": "ffmpeg_download_stream", "original_string": "def ffmpeg_download_stream(files, title, ext, params={}, output_dir='.', stream=True):\n    \"\"\"str, str->True\n    WARNING: NOT THE SAME PARMS AS OTHER FUNCTIONS!!!!!!\n    You can basicly download anything with this function\n    but better leave it alone with\n    \"\"\"\n    output = title + '.' + ext\n\n    if not (output_dir == '.'):\n        output = output_dir + '/' + output\n\n    print('Downloading streaming content with FFmpeg, press q to stop recording...')\n    if stream:\n        ffmpeg_params = [FFMPEG] + ['-y', '-re', '-i']\n    else:\n        ffmpeg_params = [FFMPEG] + ['-y', '-i']\n    ffmpeg_params.append(files)  #not the same here!!!!\n\n    if FFMPEG == 'avconv':  #who cares?\n        ffmpeg_params += ['-c', 'copy', output]\n    else:\n        ffmpeg_params += ['-c', 'copy', '-bsf:a', 'aac_adtstoasc']\n\n    if params is not None:\n        if len(params) > 0:\n            for k, v in params:\n                ffmpeg_params.append(k)\n                ffmpeg_params.append(v)\n\n    ffmpeg_params.append(output)\n\n    print(' '.join(ffmpeg_params))\n\n    try:\n        a = subprocess.Popen(ffmpeg_params, stdin= subprocess.PIPE)\n        a.communicate()\n    except KeyboardInterrupt:\n        try:\n            a.stdin.write('q'.encode('utf-8'))\n        except:\n            pass\n\n    return True", "language": "python", "code": "def ffmpeg_download_stream(files, title, ext, params={}, output_dir='.', stream=True):\n    \"\"\"str, str->True\n    WARNING: NOT THE SAME PARMS AS OTHER FUNCTIONS!!!!!!\n    You can basicly download anything with this function\n    but better leave it alone with\n    \"\"\"\n    output = title + '.' + ext\n\n    if not (output_dir == '.'):\n        output = output_dir + '/' + output\n\n    print('Downloading streaming content with FFmpeg, press q to stop recording...')\n    if stream:\n        ffmpeg_params = [FFMPEG] + ['-y', '-re', '-i']\n    else:\n        ffmpeg_params = [FFMPEG] + ['-y', '-i']\n    ffmpeg_params.append(files)  #not the same here!!!!\n\n    if FFMPEG == 'avconv':  #who cares?\n        ffmpeg_params += ['-c', 'copy', output]\n    else:\n        ffmpeg_params += ['-c', 'copy', '-bsf:a', 'aac_adtstoasc']\n\n    if params is not None:\n        if len(params) > 0:\n            for k, v in params:\n                ffmpeg_params.append(k)\n                ffmpeg_params.append(v)\n\n    ffmpeg_params.append(output)\n\n    print(' '.join(ffmpeg_params))\n\n    try:\n        a = subprocess.Popen(ffmpeg_params, stdin= subprocess.PIPE)\n        a.communicate()\n    except KeyboardInterrupt:\n        try:\n            a.stdin.write('q'.encode('utf-8'))\n        except:\n            pass\n\n    return True", "code_tokens": ["def", "ffmpeg_download_stream", "(", "files", ",", "title", ",", "ext", ",", "params", "=", "{", "}", ",", "output_dir", "=", "'.'", ",", "stream", "=", "True", ")", ":", "output", "=", "title", "+", "'.'", "+", "ext", "if", "not", "(", "output_dir", "==", "'.'", ")", ":", "output", "=", "output_dir", "+", "'/'", "+", "output", "print", "(", "'Downloading streaming content with FFmpeg, press q to stop recording...'", ")", "if", "stream", ":", "ffmpeg_params", "=", "[", "FFMPEG", "]", "+", "[", "'-y'", ",", "'-re'", ",", "'-i'", "]", "else", ":", "ffmpeg_params", "=", "[", "FFMPEG", "]", "+", "[", "'-y'", ",", "'-i'", "]", "ffmpeg_params", ".", "append", "(", "files", ")", "#not the same here!!!!", "if", "FFMPEG", "==", "'avconv'", ":", "#who cares?", "ffmpeg_params", "+=", "[", "'-c'", ",", "'copy'", ",", "output", "]", "else", ":", "ffmpeg_params", "+=", "[", "'-c'", ",", "'copy'", ",", "'-bsf:a'", ",", "'aac_adtstoasc'", "]", "if", "params", "is", "not", "None", ":", "if", "len", "(", "params", ")", ">", "0", ":", "for", "k", ",", "v", "in", "params", ":", "ffmpeg_params", ".", "append", "(", "k", ")", "ffmpeg_params", ".", "append", "(", "v", ")", "ffmpeg_params", ".", "append", "(", "output", ")", "print", "(", "' '", ".", "join", "(", "ffmpeg_params", ")", ")", "try", ":", "a", "=", "subprocess", ".", "Popen", "(", "ffmpeg_params", ",", "stdin", "=", "subprocess", ".", "PIPE", ")", "a", ".", "communicate", "(", ")", "except", "KeyboardInterrupt", ":", "try", ":", "a", ".", "stdin", ".", "write", "(", "'q'", ".", "encode", "(", "'utf-8'", ")", ")", "except", ":", "pass", "return", "True"], "docstring": "str, str->True\n    WARNING: NOT THE SAME PARMS AS OTHER FUNCTIONS!!!!!!\n    You can basicly download anything with this function\n    but better leave it alone with", "docstring_tokens": ["str", "str", "-", ">", "True", "WARNING", ":", "NOT", "THE", "SAME", "PARMS", "AS", "OTHER", "FUNCTIONS!!!!!!", "You", "can", "basicly", "download", "anything", "with", "this", "function", "but", "better", "leave", "it", "alone", "with"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/processor/ffmpeg.py#L220-L262", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "match1", "original_string": "def match1(text, *patterns):\n    \"\"\"Scans through a string for substrings matched some patterns (first-subgroups only).\n\n    Args:\n        text: A string to be scanned.\n        patterns: Arbitrary number of regex patterns.\n\n    Returns:\n        When only one pattern is given, returns a string (None if no match found).\n        When more than one pattern are given, returns a list of strings ([] if no match found).\n    \"\"\"\n\n    if len(patterns) == 1:\n        pattern = patterns[0]\n        match = re.search(pattern, text)\n        if match:\n            return match.group(1)\n        else:\n            return None\n    else:\n        ret = []\n        for pattern in patterns:\n            match = re.search(pattern, text)\n            if match:\n                ret.append(match.group(1))\n        return ret", "language": "python", "code": "def match1(text, *patterns):\n    \"\"\"Scans through a string for substrings matched some patterns (first-subgroups only).\n\n    Args:\n        text: A string to be scanned.\n        patterns: Arbitrary number of regex patterns.\n\n    Returns:\n        When only one pattern is given, returns a string (None if no match found).\n        When more than one pattern are given, returns a list of strings ([] if no match found).\n    \"\"\"\n\n    if len(patterns) == 1:\n        pattern = patterns[0]\n        match = re.search(pattern, text)\n        if match:\n            return match.group(1)\n        else:\n            return None\n    else:\n        ret = []\n        for pattern in patterns:\n            match = re.search(pattern, text)\n            if match:\n                ret.append(match.group(1))\n        return ret", "code_tokens": ["def", "match1", "(", "text", ",", "*", "patterns", ")", ":", "if", "len", "(", "patterns", ")", "==", "1", ":", "pattern", "=", "patterns", "[", "0", "]", "match", "=", "re", ".", "search", "(", "pattern", ",", "text", ")", "if", "match", ":", "return", "match", ".", "group", "(", "1", ")", "else", ":", "return", "None", "else", ":", "ret", "=", "[", "]", "for", "pattern", "in", "patterns", ":", "match", "=", "re", ".", "search", "(", "pattern", ",", "text", ")", "if", "match", ":", "ret", ".", "append", "(", "match", ".", "group", "(", "1", ")", ")", "return", "ret"], "docstring": "Scans through a string for substrings matched some patterns (first-subgroups only).\n\n    Args:\n        text: A string to be scanned.\n        patterns: Arbitrary number of regex patterns.\n\n    Returns:\n        When only one pattern is given, returns a string (None if no match found).\n        When more than one pattern are given, returns a list of strings ([] if no match found).", "docstring_tokens": ["Scans", "through", "a", "string", "for", "substrings", "matched", "some", "patterns", "(", "first", "-", "subgroups", "only", ")", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L224-L249", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "matchall", "original_string": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret", "language": "python", "code": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret", "code_tokens": ["def", "matchall", "(", "text", ",", "patterns", ")", ":", "ret", "=", "[", "]", "for", "pattern", "in", "patterns", ":", "match", "=", "re", ".", "findall", "(", "pattern", ",", "text", ")", "ret", "+=", "match", "return", "ret"], "docstring": "Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.", "docstring_tokens": ["Scans", "through", "a", "string", "for", "substrings", "matched", "some", "patterns", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L252-L268", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "parse_query_param", "original_string": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None", "language": "python", "code": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None", "code_tokens": ["def", "parse_query_param", "(", "url", ",", "param", ")", ":", "try", ":", "return", "parse", ".", "parse_qs", "(", "parse", ".", "urlparse", "(", "url", ")", ".", "query", ")", "[", "param", "]", "[", "0", "]", "except", ":", "return", "None"], "docstring": "Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.", "docstring_tokens": ["Parses", "the", "query", "string", "of", "a", "URL", "and", "returns", "the", "value", "of", "a", "parameter", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L285-L299", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "ungzip", "original_string": "def ungzip(data):\n    \"\"\"Decompresses data for Content-Encoding: gzip.\n    \"\"\"\n    from io import BytesIO\n    import gzip\n    buffer = BytesIO(data)\n    f = gzip.GzipFile(fileobj=buffer)\n    return f.read()", "language": "python", "code": "def ungzip(data):\n    \"\"\"Decompresses data for Content-Encoding: gzip.\n    \"\"\"\n    from io import BytesIO\n    import gzip\n    buffer = BytesIO(data)\n    f = gzip.GzipFile(fileobj=buffer)\n    return f.read()", "code_tokens": ["def", "ungzip", "(", "data", ")", ":", "from", "io", "import", "BytesIO", "import", "gzip", "buffer", "=", "BytesIO", "(", "data", ")", "f", "=", "gzip", ".", "GzipFile", "(", "fileobj", "=", "buffer", ")", "return", "f", ".", "read", "(", ")"], "docstring": "Decompresses data for Content-Encoding: gzip.", "docstring_tokens": ["Decompresses", "data", "for", "Content", "-", "Encoding", ":", "gzip", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L319-L326", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "undeflate", "original_string": "def undeflate(data):\n    \"\"\"Decompresses data for Content-Encoding: deflate.\n    (the zlib compression is used.)\n    \"\"\"\n    import zlib\n    decompressobj = zlib.decompressobj(-zlib.MAX_WBITS)\n    return decompressobj.decompress(data)+decompressobj.flush()", "language": "python", "code": "def undeflate(data):\n    \"\"\"Decompresses data for Content-Encoding: deflate.\n    (the zlib compression is used.)\n    \"\"\"\n    import zlib\n    decompressobj = zlib.decompressobj(-zlib.MAX_WBITS)\n    return decompressobj.decompress(data)+decompressobj.flush()", "code_tokens": ["def", "undeflate", "(", "data", ")", ":", "import", "zlib", "decompressobj", "=", "zlib", ".", "decompressobj", "(", "-", "zlib", ".", "MAX_WBITS", ")", "return", "decompressobj", ".", "decompress", "(", "data", ")", "+", "decompressobj", ".", "flush", "(", ")"], "docstring": "Decompresses data for Content-Encoding: deflate.\n    (the zlib compression is used.)", "docstring_tokens": ["Decompresses", "data", "for", "Content", "-", "Encoding", ":", "deflate", ".", "(", "the", "zlib", "compression", "is", "used", ".", ")"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L329-L335", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "get_content", "original_string": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data", "language": "python", "code": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data", "code_tokens": ["def", "get_content", "(", "url", ",", "headers", "=", "{", "}", ",", "decoded", "=", "True", ")", ":", "logging", ".", "debug", "(", "'get_content: %s'", "%", "url", ")", "req", "=", "request", ".", "Request", "(", "url", ",", "headers", "=", "headers", ")", "if", "cookies", ":", "cookies", ".", "add_cookie_header", "(", "req", ")", "req", ".", "headers", ".", "update", "(", "req", ".", "unredirected_hdrs", ")", "response", "=", "urlopen_with_retry", "(", "req", ")", "data", "=", "response", ".", "read", "(", ")", "# Handle HTTP compression for gzip and deflate (zlib)", "content_encoding", "=", "response", ".", "getheader", "(", "'Content-Encoding'", ")", "if", "content_encoding", "==", "'gzip'", ":", "data", "=", "ungzip", "(", "data", ")", "elif", "content_encoding", "==", "'deflate'", ":", "data", "=", "undeflate", "(", "data", ")", "# Decode the response body", "if", "decoded", ":", "charset", "=", "match1", "(", "response", ".", "getheader", "(", "'Content-Type'", ",", "''", ")", ",", "r'charset=([\\w-]+)'", ")", "if", "charset", "is", "not", "None", ":", "data", "=", "data", ".", "decode", "(", "charset", ",", "'ignore'", ")", "else", ":", "data", "=", "data", ".", "decode", "(", "'utf-8'", ",", "'ignore'", ")", "return", "data"], "docstring": "Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.", "docstring_tokens": ["Gets", "the", "content", "of", "a", "URL", "via", "sending", "a", "HTTP", "GET", "request", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L415-L454", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "post_content", "original_string": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data", "language": "python", "code": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data", "code_tokens": ["def", "post_content", "(", "url", ",", "headers", "=", "{", "}", ",", "post_data", "=", "{", "}", ",", "decoded", "=", "True", ",", "*", "*", "kwargs", ")", ":", "if", "kwargs", ".", "get", "(", "'post_data_raw'", ")", ":", "logging", ".", "debug", "(", "'post_content: %s\\npost_data_raw: %s'", "%", "(", "url", ",", "kwargs", "[", "'post_data_raw'", "]", ")", ")", "else", ":", "logging", ".", "debug", "(", "'post_content: %s\\npost_data: %s'", "%", "(", "url", ",", "post_data", ")", ")", "req", "=", "request", ".", "Request", "(", "url", ",", "headers", "=", "headers", ")", "if", "cookies", ":", "cookies", ".", "add_cookie_header", "(", "req", ")", "req", ".", "headers", ".", "update", "(", "req", ".", "unredirected_hdrs", ")", "if", "kwargs", ".", "get", "(", "'post_data_raw'", ")", ":", "post_data_enc", "=", "bytes", "(", "kwargs", "[", "'post_data_raw'", "]", ",", "'utf-8'", ")", "else", ":", "post_data_enc", "=", "bytes", "(", "parse", ".", "urlencode", "(", "post_data", ")", ",", "'utf-8'", ")", "response", "=", "urlopen_with_retry", "(", "req", ",", "data", "=", "post_data_enc", ")", "data", "=", "response", ".", "read", "(", ")", "# Handle HTTP compression for gzip and deflate (zlib)", "content_encoding", "=", "response", ".", "getheader", "(", "'Content-Encoding'", ")", "if", "content_encoding", "==", "'gzip'", ":", "data", "=", "ungzip", "(", "data", ")", "elif", "content_encoding", "==", "'deflate'", ":", "data", "=", "undeflate", "(", "data", ")", "# Decode the response body", "if", "decoded", ":", "charset", "=", "match1", "(", "response", ".", "getheader", "(", "'Content-Type'", ")", ",", "r'charset=([\\w-]+)'", ")", "if", "charset", "is", "not", "None", ":", "data", "=", "data", ".", "decode", "(", "charset", ")", "else", ":", "data", "=", "data", ".", "decode", "(", "'utf-8'", ")", "return", "data"], "docstring": "Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.", "docstring_tokens": ["Post", "the", "content", "of", "a", "URL", "via", "sending", "a", "HTTP", "POST", "request", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L457-L501", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "parse_host", "original_string": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)", "language": "python", "code": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)", "code_tokens": ["def", "parse_host", "(", "host", ")", ":", "if", "re", ".", "match", "(", "r'^(\\d+)$'", ",", "host", ")", "is", "not", "None", ":", "return", "(", "\"0.0.0.0\"", ",", "int", "(", "host", ")", ")", "if", "re", ".", "match", "(", "r'^(\\w+)://'", ",", "host", ")", "is", "None", ":", "host", "=", "\"//\"", "+", "host", "o", "=", "parse", ".", "urlparse", "(", "host", ")", "hostname", "=", "o", ".", "hostname", "or", "\"0.0.0.0\"", "port", "=", "o", ".", "port", "or", "0", "return", "(", "hostname", ",", "port", ")"], "docstring": "Parses host name and port number from a string.", "docstring_tokens": ["Parses", "host", "name", "and", "port", "number", "from", "a", "string", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L1216-L1226", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/common.py", "func_name": "print_more_compatible", "original_string": "def print_more_compatible(*args, **kwargs):\n    import builtins as __builtin__\n    \"\"\"Overload default print function as py (<3.3) does not support 'flush' keyword.\n    Although the function name can be same as print to get itself overloaded automatically,\n    I'd rather leave it with a different name and only overload it when importing to make less confusion.\n    \"\"\"\n    # nothing happens on py3.3 and later\n    if sys.version_info[:2] >= (3, 3):\n        return __builtin__.print(*args, **kwargs)\n\n    # in lower pyver (e.g. 3.2.x), remove 'flush' keyword and flush it as requested\n    doFlush = kwargs.pop('flush', False)\n    ret = __builtin__.print(*args, **kwargs)\n    if doFlush:\n        kwargs.get('file', sys.stdout).flush()\n    return ret", "language": "python", "code": "def print_more_compatible(*args, **kwargs):\n    import builtins as __builtin__\n    \"\"\"Overload default print function as py (<3.3) does not support 'flush' keyword.\n    Although the function name can be same as print to get itself overloaded automatically,\n    I'd rather leave it with a different name and only overload it when importing to make less confusion.\n    \"\"\"\n    # nothing happens on py3.3 and later\n    if sys.version_info[:2] >= (3, 3):\n        return __builtin__.print(*args, **kwargs)\n\n    # in lower pyver (e.g. 3.2.x), remove 'flush' keyword and flush it as requested\n    doFlush = kwargs.pop('flush', False)\n    ret = __builtin__.print(*args, **kwargs)\n    if doFlush:\n        kwargs.get('file', sys.stdout).flush()\n    return ret", "code_tokens": ["def", "print_more_compatible", "(", "*", "args", ",", "*", "*", "kwargs", ")", ":", "import", "builtins", "as", "__builtin__", "# nothing happens on py3.3 and later", "if", "sys", ".", "version_info", "[", ":", "2", "]", ">=", "(", "3", ",", "3", ")", ":", "return", "__builtin__", ".", "print", "(", "*", "args", ",", "*", "*", "kwargs", ")", "# in lower pyver (e.g. 3.2.x), remove 'flush' keyword and flush it as requested", "doFlush", "=", "kwargs", ".", "pop", "(", "'flush'", ",", "False", ")", "ret", "=", "__builtin__", ".", "print", "(", "*", "args", ",", "*", "*", "kwargs", ")", "if", "doFlush", ":", "kwargs", ".", "get", "(", "'file'", ",", "sys", ".", "stdout", ")", ".", "flush", "(", ")", "return", "ret"], "docstring": "Overload default print function as py (<3.3) does not support 'flush' keyword.\n    Although the function name can be same as print to get itself overloaded automatically,\n    I'd rather leave it with a different name and only overload it when importing to make less confusion.", "docstring_tokens": ["Overload", "default", "print", "function", "as", "py", "(", "<3", ".", "3", ")", "does", "not", "support", "flush", "keyword", ".", "Although", "the", "function", "name", "can", "be", "same", "as", "print", "to", "get", "itself", "overloaded", "automatically", "I", "d", "rather", "leave", "it", "with", "a", "different", "name", "and", "only", "overload", "it", "when", "importing", "to", "make", "less", "confusion", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L1258-L1273", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/showroom.py", "func_name": "showroom_get_roomid_by_room_url_key", "original_string": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid", "language": "python", "code": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid", "code_tokens": ["def", "showroom_get_roomid_by_room_url_key", "(", "room_url_key", ")", ":", "fake_headers_mobile", "=", "{", "'Accept'", ":", "'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'", ",", "'Accept-Charset'", ":", "'UTF-8,*;q=0.5'", ",", "'Accept-Encoding'", ":", "'gzip,deflate,sdch'", ",", "'Accept-Language'", ":", "'en-US,en;q=0.8'", ",", "'User-Agent'", ":", "'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'", "}", "webpage_url", "=", "'https://www.showroom-live.com/'", "+", "room_url_key", "html", "=", "get_content", "(", "webpage_url", ",", "headers", "=", "fake_headers_mobile", ")", "roomid", "=", "match1", "(", "html", ",", "r'room\\?room_id\\=(\\d+)'", ")", "assert", "roomid", "return", "roomid"], "docstring": "str->str", "docstring_tokens": ["str", "-", ">", "str"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/showroom.py#L11-L24", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/showroom.py", "func_name": "showroom_download_by_room_id", "original_string": "def showroom_download_by_room_id(room_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    while True:\n        timestamp = str(int(time() * 1000))\n        api_endpoint = 'https://www.showroom-live.com/api/live/streaming_url?room_id={room_id}&_={timestamp}'.format(room_id = room_id, timestamp = timestamp)\n        html = get_content(api_endpoint)\n        html = json.loads(html)\n        #{'streaming_url_list': [{'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 1, 'label': 'original spec(low latency)', 'is_default': True, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed/playlist.m3u8', 'is_default': True, 'id': 2, 'type': 'hls', 'label': 'original spec'}, {'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 3, 'label': 'low spec(low latency)', 'is_default': False, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low/playlist.m3u8', 'is_default': False, 'id': 4, 'type': 'hls', 'label': 'low spec'}]}\n        if len(html) >= 1:\n            break\n        log.w('The live show is currently offline.')\n        sleep(1)\n\n    #This is mainly for testing the M3U FFmpeg parser so I would ignore any non-m3u ones\n    stream_url = [i['url'] for i in html['streaming_url_list'] if i['is_default'] and i['type'] == 'hls'][0]\n\n    assert stream_url\n\n    #title\n    title = ''\n    profile_api = 'https://www.showroom-live.com/api/room/profile?room_id={room_id}'.format(room_id = room_id)\n    html = loads(get_content(profile_api))\n    try:\n        title = html['main_name']\n    except KeyError:\n        title = 'Showroom_{room_id}'.format(room_id = room_id)\n\n    type_, ext, size = url_info(stream_url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_url_ffmpeg(url=stream_url, title=title, ext= 'mp4', output_dir=output_dir)", "language": "python", "code": "def showroom_download_by_room_id(room_id, output_dir = '.', merge = False, info_only = False, **kwargs):\n    '''Source: Android mobile'''\n    while True:\n        timestamp = str(int(time() * 1000))\n        api_endpoint = 'https://www.showroom-live.com/api/live/streaming_url?room_id={room_id}&_={timestamp}'.format(room_id = room_id, timestamp = timestamp)\n        html = get_content(api_endpoint)\n        html = json.loads(html)\n        #{'streaming_url_list': [{'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 1, 'label': 'original spec(low latency)', 'is_default': True, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed/playlist.m3u8', 'is_default': True, 'id': 2, 'type': 'hls', 'label': 'original spec'}, {'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 3, 'label': 'low spec(low latency)', 'is_default': False, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low/playlist.m3u8', 'is_default': False, 'id': 4, 'type': 'hls', 'label': 'low spec'}]}\n        if len(html) >= 1:\n            break\n        log.w('The live show is currently offline.')\n        sleep(1)\n\n    #This is mainly for testing the M3U FFmpeg parser so I would ignore any non-m3u ones\n    stream_url = [i['url'] for i in html['streaming_url_list'] if i['is_default'] and i['type'] == 'hls'][0]\n\n    assert stream_url\n\n    #title\n    title = ''\n    profile_api = 'https://www.showroom-live.com/api/room/profile?room_id={room_id}'.format(room_id = room_id)\n    html = loads(get_content(profile_api))\n    try:\n        title = html['main_name']\n    except KeyError:\n        title = 'Showroom_{room_id}'.format(room_id = room_id)\n\n    type_, ext, size = url_info(stream_url)\n    print_info(site_info, title, type_, size)\n    if not info_only:\n        download_url_ffmpeg(url=stream_url, title=title, ext= 'mp4', output_dir=output_dir)", "code_tokens": ["def", "showroom_download_by_room_id", "(", "room_id", ",", "output_dir", "=", "'.'", ",", "merge", "=", "False", ",", "info_only", "=", "False", ",", "*", "*", "kwargs", ")", ":", "while", "True", ":", "timestamp", "=", "str", "(", "int", "(", "time", "(", ")", "*", "1000", ")", ")", "api_endpoint", "=", "'https://www.showroom-live.com/api/live/streaming_url?room_id={room_id}&_={timestamp}'", ".", "format", "(", "room_id", "=", "room_id", ",", "timestamp", "=", "timestamp", ")", "html", "=", "get_content", "(", "api_endpoint", ")", "html", "=", "json", ".", "loads", "(", "html", ")", "#{'streaming_url_list': [{'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 1, 'label': 'original spec(low latency)', 'is_default': True, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed/playlist.m3u8', 'is_default': True, 'id': 2, 'type': 'hls', 'label': 'original spec'}, {'url': 'rtmp://52.197.69.198:1935/liveedge', 'id': 3, 'label': 'low spec(low latency)', 'is_default': False, 'type': 'rtmp', 'stream_name': '7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low'}, {'url': 'http://52.197.69.198:1935/liveedge/7656a6d5baa1d77075c971f6d8b6dc61b979fc913dc5fe7cc1318281793436ed_low/playlist.m3u8', 'is_default': False, 'id': 4, 'type': 'hls', 'label': 'low spec'}]}", "if", "len", "(", "html", ")", ">=", "1", ":", "break", "log", ".", "w", "(", "'The live show is currently offline.'", ")", "sleep", "(", "1", ")", "#This is mainly for testing the M3U FFmpeg parser so I would ignore any non-m3u ones", "stream_url", "=", "[", "i", "[", "'url'", "]", "for", "i", "in", "html", "[", "'streaming_url_list'", "]", "if", "i", "[", "'is_default'", "]", "and", "i", "[", "'type'", "]", "==", "'hls'", "]", "[", "0", "]", "assert", "stream_url", "#title", "title", "=", "''", "profile_api", "=", "'https://www.showroom-live.com/api/room/profile?room_id={room_id}'", ".", "format", "(", "room_id", "=", "room_id", ")", "html", "=", "loads", "(", "get_content", "(", "profile_api", ")", ")", "try", ":", "title", "=", "html", "[", "'main_name'", "]", "except", "KeyError", ":", "title", "=", "'Showroom_{room_id}'", ".", "format", "(", "room_id", "=", "room_id", ")", "type_", ",", "ext", ",", "size", "=", "url_info", "(", "stream_url", ")", "print_info", "(", "site_info", ",", "title", ",", "type_", ",", "size", ")", "if", "not", "info_only", ":", "download_url_ffmpeg", "(", "url", "=", "stream_url", ",", "title", "=", "title", ",", "ext", "=", "'mp4'", ",", "output_dir", "=", "output_dir", ")"], "docstring": "Source: Android mobile", "docstring_tokens": ["Source", ":", "Android", "mobile"], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/showroom.py#L26-L56", "partition": "test"}
{"repo": "soimort/you-get", "path": "src/you_get/extractors/wanmen.py", "func_name": "_wanmen_get_title_by_json_topic_part", "original_string": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])", "language": "python", "code": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])", "code_tokens": ["def", "_wanmen_get_title_by_json_topic_part", "(", "json_content", ",", "tIndex", ",", "pIndex", ")", ":", "return", "'_'", ".", "join", "(", "[", "json_content", "[", "0", "]", "[", "'name'", "]", ",", "json_content", "[", "0", "]", "[", "'Topics'", "]", "[", "tIndex", "]", "[", "'name'", "]", ",", "json_content", "[", "0", "]", "[", "'Topics'", "]", "[", "tIndex", "]", "[", "'Parts'", "]", "[", "pIndex", "]", "[", "'name'", "]", "]", ")"], "docstring": "JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.", "docstring_tokens": ["JSON", "int", "int", "int", "-", ">", "str", "Get", "a", "proper", "title", "with", "courseid", "+", "topicID", "+", "partID", "."], "sha": "b746ac01c9f39de94cac2d56f665285b0523b974", "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L18-L25", "partition": "test"}
